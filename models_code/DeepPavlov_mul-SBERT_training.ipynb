{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "660d41e34e5a4be8b4c60ed9467919f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c29c5507fd448b3bc600c0f82a189c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8f0a10d8695472292a182a596bb4ae2",
              "IPY_MODEL_bd6e2d1986f04e468406a08a971075d4"
            ]
          }
        },
        "1c29c5507fd448b3bc600c0f82a189c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8f0a10d8695472292a182a596bb4ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ff997c0ad7d45578b45c051924ba04a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0125c85dcf243eb97f7615d0be3181c"
          }
        },
        "bd6e2d1986f04e468406a08a971075d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7eaff040112b4253bfa3869eefacc025",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:02&lt;00:00, 335kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2425a7da177340dabdd9e1822dfb23eb"
          }
        },
        "5ff997c0ad7d45578b45c051924ba04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0125c85dcf243eb97f7615d0be3181c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7eaff040112b4253bfa3869eefacc025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2425a7da177340dabdd9e1822dfb23eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "082ec0069a8449c4956e51449c0fc3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4eab046c0b0f4f90a33b16380d18786e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fcac7f8a74e346019c420927441e6175",
              "IPY_MODEL_ea85e45d853e4f9aa989b85ee0fe952f"
            ]
          }
        },
        "4eab046c0b0f4f90a33b16380d18786e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcac7f8a74e346019c420927441e6175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae9eccd3740247e6a09d9b2a905e21a8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8054db400a0448cb9c7801406fa5ba73"
          }
        },
        "ea85e45d853e4f9aa989b85ee0fe952f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3538edb0237b4132b7a1e0e8706d88a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:01&lt;00:00, 92.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b07d99ca415244c895519d9386388367"
          }
        },
        "ae9eccd3740247e6a09d9b2a905e21a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8054db400a0448cb9c7801406fa5ba73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3538edb0237b4132b7a1e0e8706d88a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b07d99ca415244c895519d9386388367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1db1cadefdf4befaeb7633123a085e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56258356a19345199748594e49ee7817",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_864b6f64c54f4039ac3203514e8602a9",
              "IPY_MODEL_b72b5b1c469a47f293ae7539f3bfbb1a"
            ]
          }
        },
        "56258356a19345199748594e49ee7817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "864b6f64c54f4039ac3203514e8602a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8554b2c2bc347cbb6930260f6426aef",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_390149d6b0e146288070ae66f1e63688"
          }
        },
        "b72b5b1c469a47f293ae7539f3bfbb1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b88ecf237964f2a8700147e6b03bc1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24.0/24.0 [00:00&lt;00:00, 161B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5714b7bf034447beab5c2f816e172f18"
          }
        },
        "c8554b2c2bc347cbb6930260f6426aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "390149d6b0e146288070ae66f1e63688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b88ecf237964f2a8700147e6b03bc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5714b7bf034447beab5c2f816e172f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e041969bd6b646c2ac6937c15cd7736c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34ca139f7f97450fac65e0f234bde9d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb30341b854543a5938a2e2ebc9eb636",
              "IPY_MODEL_b625fb6fe0dc483f99676ebf626ad6a4"
            ]
          }
        },
        "34ca139f7f97450fac65e0f234bde9d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "eb30341b854543a5938a2e2ebc9eb636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41cd1ea622d647f49c065a45fcdc4bbc",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcaf98196c9e4ea8829688d01e808c7b"
          }
        },
        "b625fb6fe0dc483f99676ebf626ad6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a717ff409ceb441b9fd416d2431120fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:01&lt;00:00,  1.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a141d9b5a6f84fb4b385251b4cfc4c48"
          }
        },
        "41cd1ea622d647f49c065a45fcdc4bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcaf98196c9e4ea8829688d01e808c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a717ff409ceb441b9fd416d2431120fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a141d9b5a6f84fb4b385251b4cfc4c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7bf967352824648a0f4cff9ba5d3eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_136e2f58ea6c4bcabff9bea03027e313",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bd99dfaf579489ab797157171fb5791",
              "IPY_MODEL_b4d7dc8eb9684740b95ee9a65c977eb4"
            ]
          }
        },
        "136e2f58ea6c4bcabff9bea03027e313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "0bd99dfaf579489ab797157171fb5791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ceb651d0c13469bbd79feec6a9b2d25",
            "_dom_classes": [],
            "description": "Epoch 5: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 23896,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23896,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b9e134276074e0196216c1caa91c12a"
          }
        },
        "b4d7dc8eb9684740b95ee9a65c977eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bb5692804124b0e9a01e981143f0d04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 23896/23896 [2:42:21&lt;00:00,  2.45it/s, loss=0.285, v_num=3d8rtrp5]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a68bb9ece1b94a8d8c8f210342b0a6ef"
          }
        },
        "3ceb651d0c13469bbd79feec6a9b2d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b9e134276074e0196216c1caa91c12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bb5692804124b0e9a01e981143f0d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a68bb9ece1b94a8d8c8f210342b0a6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e570c93e216e4280aeda4cbcef5aa4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d1562d56e6449bc8e4631cdc788d5a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_260240d7033748d2a407aaa5286a01ea",
              "IPY_MODEL_6a5cd25a06964050937ff7b770834e2d"
            ]
          }
        },
        "9d1562d56e6449bc8e4631cdc788d5a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "260240d7033748d2a407aaa5286a01ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90ef5a63c94a4a65ae7e99c7baece065",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85078bfc7e1048b4930eee89425b7f4a"
          }
        },
        "6a5cd25a06964050937ff7b770834e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54b9e4d8a90047beba5db0cc940ef13a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5974/5974 [19:05&lt;00:00,  8.65it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e8697df4fb74a81a0be455eb3afc812"
          }
        },
        "90ef5a63c94a4a65ae7e99c7baece065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85078bfc7e1048b4930eee89425b7f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54b9e4d8a90047beba5db0cc940ef13a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e8697df4fb74a81a0be455eb3afc812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58033e3b09924e27abe92dc390291256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ac1cdd9e5244416b60c7a38d0ef32d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7634c24ce8a487f8f14264a78143988",
              "IPY_MODEL_ebba4e7f69cb4f21b1e7784ccb9abfe5"
            ]
          }
        },
        "4ac1cdd9e5244416b60c7a38d0ef32d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b7634c24ce8a487f8f14264a78143988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62972f5fa2e8481ab5e75ee206f80ce4",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf40819370724952b00936fa2f498fa3"
          }
        },
        "ebba4e7f69cb4f21b1e7784ccb9abfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50ca8d780ed44fd4b2cb5a4efe4f81c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5974/5974 [19:09&lt;00:00,  8.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27b132bca31f475eb9b51d005cdaf8f0"
          }
        },
        "62972f5fa2e8481ab5e75ee206f80ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf40819370724952b00936fa2f498fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50ca8d780ed44fd4b2cb5a4efe4f81c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27b132bca31f475eb9b51d005cdaf8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fb582c1e72144eebbcd145a2c8698e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4ebe1f9cc21496bac05c423cc7e052c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d92a2248197d4d44bff42e5921d7922b",
              "IPY_MODEL_74d1e1901b1c4e899ccf246a7e9fc3d6"
            ]
          }
        },
        "c4ebe1f9cc21496bac05c423cc7e052c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d92a2248197d4d44bff42e5921d7922b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_739c9a9987944fc39a5c4aa293a41946",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c3bea5bd7264cf18725ebc46f8585cc"
          }
        },
        "74d1e1901b1c4e899ccf246a7e9fc3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c369554efe745c8ad851a48c8c36190",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5974/5974 [19:02&lt;00:00,  8.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b96a85bdd50c4ce896290586d1f7d8ee"
          }
        },
        "739c9a9987944fc39a5c4aa293a41946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c3bea5bd7264cf18725ebc46f8585cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c369554efe745c8ad851a48c8c36190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b96a85bdd50c4ce896290586d1f7d8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2edc646c9b14e24888dfbe62cf715e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea8a1509ef43422d9625bf17bae10be6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cac793d473214351b372c41744efdf7b",
              "IPY_MODEL_4052413eb345412d87266fee2d303334"
            ]
          }
        },
        "ea8a1509ef43422d9625bf17bae10be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cac793d473214351b372c41744efdf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3fc7de8d6c4f4989850d9e5485e362c9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 642,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 642,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9e0ffae0b484212a8950e84fbe6b28b"
          }
        },
        "4052413eb345412d87266fee2d303334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6aca0884f9345d79dfbd3668938d8ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 642/642 [00:58&lt;00:00, 11.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81abf07c6a974484a33c5ecb7ca8bef2"
          }
        },
        "3fc7de8d6c4f4989850d9e5485e362c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9e0ffae0b484212a8950e84fbe6b28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6aca0884f9345d79dfbd3668938d8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81abf07c6a974484a33c5ecb7ca8bef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52a995c7aebf4cc4864020df587440f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c89df62f97354ca6940de6d9c0b3ca35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e152ff30b094d68a9762a50135c35a9",
              "IPY_MODEL_28e765b92d7247ad8591abb726bf2930"
            ]
          }
        },
        "c89df62f97354ca6940de6d9c0b3ca35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e152ff30b094d68a9762a50135c35a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ad99e91d12f44728a177d18bdfb9dc6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 711456796,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 711456796,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6d280cf7efa4b75b7df129ae0f99fa6"
          }
        },
        "28e765b92d7247ad8591abb726bf2930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_080a50c37f414d82922164c5cac29803",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 711M/711M [00:56&lt;00:00, 12.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd93d1fd92ff4f0181a3e56548f5187a"
          }
        },
        "9ad99e91d12f44728a177d18bdfb9dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6d280cf7efa4b75b7df129ae0f99fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "080a50c37f414d82922164c5cac29803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd93d1fd92ff4f0181a3e56548f5187a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef53b39bbfda4ef2864d61ecaa865017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9d039d1f15c4a8aa0d8257a944f833e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d6d594e179842e6b3d041aeb969bd80",
              "IPY_MODEL_db210d6caa654761bfb0a8cff3337ba4"
            ]
          }
        },
        "f9d039d1f15c4a8aa0d8257a944f833e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d6d594e179842e6b3d041aeb969bd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_714a29beb6e14e2f9e1b3a95a1cf3129",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a77514e14e5945b9a8c7d92a64104c66"
          }
        },
        "db210d6caa654761bfb0a8cff3337ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3fff2b8d135341eab5dfbdfbd26cf771",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:03&lt;00:00, 274kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0e9a210bfee42f3bfdeec5ad1745e48"
          }
        },
        "714a29beb6e14e2f9e1b3a95a1cf3129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a77514e14e5945b9a8c7d92a64104c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fff2b8d135341eab5dfbdfbd26cf771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0e9a210bfee42f3bfdeec5ad1745e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bea242cb9214fbd91e13838bafa5c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f62f0250a4524a49909f367d250e26c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a940e4bfdfef4a0cb739d206117a67c9",
              "IPY_MODEL_186138a4b7e146619f41c26e7d1892e8"
            ]
          }
        },
        "f62f0250a4524a49909f367d250e26c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a940e4bfdfef4a0cb739d206117a67c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1501b145424144d9b3f270c3b421c084",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14c272347d904869b85cb3f85bd7709a"
          }
        },
        "186138a4b7e146619f41c26e7d1892e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40b5a334fa824f91bcbdb53229f3dfb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:02&lt;00:00, 53.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b5a28855def45aea377238683dbad44"
          }
        },
        "1501b145424144d9b3f270c3b421c084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14c272347d904869b85cb3f85bd7709a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40b5a334fa824f91bcbdb53229f3dfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b5a28855def45aea377238683dbad44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "523eeebd529b4274ada0c052e6e277d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b0e243aafa2464496136b2e38679eae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d18f27fbc18643a89b59bb414cc699b0",
              "IPY_MODEL_34d9a985216645a8b6d9ce64b9945f67"
            ]
          }
        },
        "6b0e243aafa2464496136b2e38679eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d18f27fbc18643a89b59bb414cc699b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a652e14fef44847af86d49bd37f910d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46535a077cfe4aeba731169c3c2de74c"
          }
        },
        "34d9a985216645a8b6d9ce64b9945f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f00a70c8d604529909af0b4e8eec3c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24.0/24.0 [00:00&lt;00:00, 154B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0064436c6fd04db99be0270f9659922b"
          }
        },
        "8a652e14fef44847af86d49bd37f910d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46535a077cfe4aeba731169c3c2de74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f00a70c8d604529909af0b4e8eec3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0064436c6fd04db99be0270f9659922b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_EiHka9RP6B",
        "colab_type": "code",
        "outputId": "55ebc060-23b9-4e59-ff71-d5408ce6ca02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAgFaHDJ-wC7",
        "colab_type": "code",
        "outputId": "b1bd234c-b230-451c-cdb6-799d1404a6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=f26f2c4439e69b462031e71ddb7c91bddf0c91bd1eeeccbbc8d78c3f2caa9010\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 282.4 MB\n",
            "GPU RAM Free: 16270MB | Used: 10MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "554LXdS6zGeF",
        "colab_type": "code",
        "outputId": "9894cf28-cdcf-4de5-d11f-a66d0642191b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "!unzip drive/My\\ Drive/Colab\\ Notebooks/DeepPavlov_mul-SBERT.zip "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/Colab Notebooks/DeepPavlov_mul-SBERT.zip\n",
            "   creating: DeepPavlov_mul-SBERT/\n",
            "   creating: DeepPavlov_mul-SBERT/data/\n",
            "  inflating: DeepPavlov_mul-SBERT/data/label_weights.pkl  \n",
            "  inflating: DeepPavlov_mul-SBERT/data/train.parquet  \n",
            "  inflating: DeepPavlov_mul-SBERT/data/test.parquet  \n",
            "  inflating: DeepPavlov_mul-SBERT/data/val.parquet  \n",
            "   creating: DeepPavlov_mul-SBERT/source/\n",
            "  inflating: DeepPavlov_mul-SBERT/source/model.py  \n",
            "  inflating: DeepPavlov_mul-SBERT/source/eval.py  \n",
            "  inflating: DeepPavlov_mul-SBERT/source/config.py  \n",
            "  inflating: DeepPavlov_mul-SBERT/source/train.py  \n",
            "  inflating: DeepPavlov_mul-SBERT/run_colab_training.py  \n",
            " extracting: DeepPavlov_mul-SBERT/requirements.in  \n",
            "  inflating: DeepPavlov_mul-SBERT/requirements.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ7_XQqjzXt0",
        "colab_type": "code",
        "outputId": "a047e44a-a5df-4111-c72f-b5230fb45b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r DeepPavlov_mul-SBERT/requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 7)) (0.9.0)\n",
            "Collecting boto3==1.13.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/76/b488ad549d3652c299e1a1f2425a0a53c55857d59fefd4598ddcd067886a/boto3-1.13.18-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.6MB/s \n",
            "\u001b[?25hCollecting botocore==1.16.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/12/2b993a5a67148454404e4e50238a23df67e28eaa7d9701580b5c9ed6ad1b/botocore-1.16.18-py2.py3-none-any.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools==4.1.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 10)) (4.1.0)\n",
            "Collecting certifi==2020.4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/2b/26e37a4b034800c960a00c4e1b3d9ca5d7014e983e6e729e33ea2f36426c/certifi-2020.4.5.1-py2.py3-none-any.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 30.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 13)) (7.1.2)\n",
            "Collecting configparser==5.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Collecting docker-pycreds==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docutils==0.15.2 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 16)) (0.15.2)\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 17)) (3.0.12)\n",
            "Collecting future==0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 34.6MB/s \n",
            "\u001b[?25hCollecting gitdb==4.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting gitpython==3.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib==0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 21)) (0.4.1)\n",
            "Collecting google-auth==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/a3/2695fdcda305ea85c43ebd2a4d1429f3c7e897c7cf9045a8c378e1115a15/google_auth-1.15.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
            "\u001b[?25hCollecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Collecting graphql-core==1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio==1.29.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 25)) (1.29.0)\n",
            "Requirement already satisfied: idna==2.9 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 26)) (2.9)\n",
            "Collecting importlib-metadata==1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/e4/891bfcaf868ccabc619942f27940c77a8a4b45fd8367098955bb7e152fb1/importlib_metadata-1.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jmespath==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 28)) (0.10.0)\n",
            "Requirement already satisfied: joblib==0.15.1 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 29)) (0.15.1)\n",
            "Requirement already satisfied: markdown==3.2.2 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 30)) (3.2.2)\n",
            "Collecting numpy==1.18.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3==7.352.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 32)) (7.352.0)\n",
            "Requirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 33)) (3.1.0)\n",
            "Collecting pathtools==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 35)) (2.3)\n",
            "Collecting protobuf==3.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/05/9867ef8eafd12265267bee138fa2c46ebf34a276ea4cbe184cba4c606e8b/protobuf-3.12.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 40.5MB/s \n",
            "\u001b[?25hCollecting psutil==5.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/b8/3512f0e93e0db23a71d82485ba256071ebef99b227351f0f5540f744af41/psutil-5.7.0.tar.gz (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 38)) (0.2.8)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 39)) (0.4.8)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 40)) (2.8.1)\n",
            "Collecting pytorch-lightning==0.7.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/ab/561d1fa6e5af30b2fd7cb4001f93eb08531e1b72976f13eebf7f7cdc021c/pytorch_lightning-0.7.6-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 38.2MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 39.2MB/s \n",
            "\u001b[?25hCollecting regex==2020.5.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/7c/0d46b10a87b3087e8e303fac923beb19ec839d7c5ea34971a12fafb22b52/regex-2020.5.14-cp36-cp36m-manylinux2010_x86_64.whl (675kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 44)) (1.3.0)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 45)) (2.23.0)\n",
            "Collecting rsa==4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: s3transfer==0.3.3 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 47)) (0.3.3)\n",
            "Collecting sacremoses==0.0.43\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 29.5MB/s \n",
            "\u001b[?25hCollecting sentry-sdk==0.14.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/95/9a20eebcedab2c1c63fad59fe19a0469edfc2a25b8576497e8084629c2ff/sentry_sdk-0.14.4-py2.py3-none-any.whl (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 46.9MB/s \n",
            "\u001b[?25hCollecting shortuuid==1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting six==1.15.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
            "Collecting smmap==3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Collecting subprocess32==3.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit==1.6.0.post3 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 55)) (1.6.0.post3)\n",
            "Collecting tensorboard==2.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/fd/4f3ca1516cbb3713259ef229abd9314bba0077ef6070285dde0dd1ed21b2/tensorboard-2.2.1-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 30.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 58)) (1.5.0+cu101)\n",
            "Collecting tqdm==4.46.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[?25hCollecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 36.9MB/s \n",
            "\u001b[?25hCollecting urllib3==1.25.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 46.7MB/s \n",
            "\u001b[?25hCollecting wandb==0.8.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/c7/8bf2c62c3f133f45e135a8a116e4e0f162043248e3db54de30996eaf1a8a/wandb-0.8.36-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 35.7MB/s \n",
            "\u001b[?25hCollecting watchdog==0.10.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 64)) (1.0.1)\n",
            "Requirement already satisfied: wheel==0.34.2 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 65)) (0.34.2)\n",
            "Requirement already satisfied: zipp==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r DeepPavlov_mul-SBERT/requirements.txt (line 66)) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth==1.15.0->-r DeepPavlov_mul-SBERT/requirements.txt (line 22)) (47.3.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0->-r DeepPavlov_mul-SBERT/requirements.txt (line 60)) (0.7)\n",
            "Building wheels for collected packages: future, gql, graphql-core, pathtools, psutil, pyyaml, sacremoses, subprocess32, watchdog\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=e28390f776806ebebb1a09ea02616377dcd307730e96dea1980e6db45e79422d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=e5d9c35032213c247c8a1e787e4ae888bacc16fd87263606d8c9bc46e9b6cbb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=75b137cdb02d136fcb509af1a475d344075eaa4d22ca1765351da3dbb2e252f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=f3cf6a08d254e6068d444a56601310489e3300b885ceb0c6bedce05c95f25cc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.0-cp36-cp36m-linux_x86_64.whl size=272690 sha256=c3ec46219819c9ed5ec8d88665400b7ce2f0de4ddd6b592f4c77d4c2f7e3ed50\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/69/b4/3200b95828d1f0ddb3cb5699083717f4fdbd9b4223d0644c57\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=524f90023cb37fc915390b4baae7c4c01603647b2929e3fa25c6f5f4bcac68c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=ed4e07a2b06be8c0d7fef2cc2c60f7aa6c52f18e4a25629b4f425b74a1d85a3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=3e5b01cc8b7487e630c85a8c3d73544e8b41dfaefd77a3b7824ac89ca300ab3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=aa751b74ea14ba5a597cff18012ee8bc7370321aa4194d60d05c55773a0849b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
            "Successfully built future gql graphql-core pathtools psutil pyyaml sacremoses subprocess32 watchdog\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.17.2, but you'll have google-auth 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3, botocore, boto3, certifi, configparser, six, docker-pycreds, future, smmap, gitdb, gitpython, rsa, google-auth, graphql-core, gql, importlib-metadata, numpy, pathtools, protobuf, psutil, tensorboard, pyyaml, tqdm, pytorch-lightning, regex, sacremoses, sentencepiece, sentry-sdk, shortuuid, subprocess32, tokenizers, transformers, watchdog, wandb\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: botocore 1.17.2\n",
            "    Uninstalling botocore-1.17.2:\n",
            "      Successfully uninstalled botocore-1.17.2\n",
            "  Found existing installation: boto3 1.14.2\n",
            "    Uninstalling boto3-1.14.2:\n",
            "      Successfully uninstalled boto3-1.14.2\n",
            "  Found existing installation: certifi 2020.4.5.2\n",
            "    Uninstalling certifi-2020.4.5.2:\n",
            "      Successfully uninstalled certifi-2020.4.5.2\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "  Found existing installation: google-auth 1.17.2\n",
            "    Uninstalling google-auth-1.17.2:\n",
            "      Successfully uninstalled google-auth-1.17.2\n",
            "  Found existing installation: importlib-metadata 1.6.1\n",
            "    Uninstalling importlib-metadata-1.6.1:\n",
            "      Successfully uninstalled importlib-metadata-1.6.1\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed boto3-1.13.18 botocore-1.16.18 certifi-2020.4.5.1 configparser-5.0.0 docker-pycreds-0.4.0 future-0.18.2 gitdb-4.0.5 gitpython-3.1.2 google-auth-1.15.0 gql-0.2.0 graphql-core-1.1 importlib-metadata-1.6.0 numpy-1.18.4 pathtools-0.1.2 protobuf-3.12.2 psutil-5.7.0 pytorch-lightning-0.7.6 pyyaml-5.3.1 regex-2020.5.14 rsa-4.0 sacremoses-0.0.43 sentencepiece-0.1.91 sentry-sdk-0.14.4 shortuuid-1.0.1 six-1.15.0 smmap-3.0.4 subprocess32-3.5.4 tensorboard-2.2.1 tokenizers-0.5.2 tqdm-4.46.0 transformers-2.8.0 urllib3-1.25.9 wandb-0.8.36 watchdog-0.10.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "google",
                  "numpy",
                  "rsa",
                  "six",
                  "tqdm",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZpPrvZ_z3w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python DeepPavlov_ru-SBERT/run_colab_training.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LFaP_Ma6AYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r DeepPavlov_mul-SBERT/source .\n",
        "!cp -r DeepPavlov_mul-SBERT/data ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzbOwzX3-dAR",
        "colab_type": "code",
        "outputId": "e368185a-40e3-484d-8101-697a089d3bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "def memory_cleanup():\n",
        "    \"\"\"\n",
        "    Cleans up GPU memory \n",
        "    https://github.com/huggingface/transformers/issues/1742\n",
        "    \"\"\"\n",
        "    for obj in gc.get_objects():\n",
        "        if torch.is_tensor(obj):\n",
        "            del obj\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "memory_cleanup()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py:102: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvzVWbWi5a_p",
        "colab_type": "code",
        "outputId": "aca3da52-9cfb-4cc0-9d62-3e97c2e282e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "from source import config, train, eval\n",
        "from source.model import ModelClass, DatasetClass"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkbaK3aq5vr_",
        "colab_type": "code",
        "outputId": "f04ba777-f654-4e51-b6c3-1c994af960a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "660d41e34e5a4be8b4c60ed9467919f8",
            "1c29c5507fd448b3bc600c0f82a189c4",
            "d8f0a10d8695472292a182a596bb4ae2",
            "bd6e2d1986f04e468406a08a971075d4",
            "5ff997c0ad7d45578b45c051924ba04a",
            "f0125c85dcf243eb97f7615d0be3181c",
            "7eaff040112b4253bfa3869eefacc025",
            "2425a7da177340dabdd9e1822dfb23eb",
            "082ec0069a8449c4956e51449c0fc3c0",
            "4eab046c0b0f4f90a33b16380d18786e",
            "fcac7f8a74e346019c420927441e6175",
            "ea85e45d853e4f9aa989b85ee0fe952f",
            "ae9eccd3740247e6a09d9b2a905e21a8",
            "8054db400a0448cb9c7801406fa5ba73",
            "3538edb0237b4132b7a1e0e8706d88a0",
            "b07d99ca415244c895519d9386388367",
            "b1db1cadefdf4befaeb7633123a085e2",
            "56258356a19345199748594e49ee7817",
            "864b6f64c54f4039ac3203514e8602a9",
            "b72b5b1c469a47f293ae7539f3bfbb1a",
            "c8554b2c2bc347cbb6930260f6426aef",
            "390149d6b0e146288070ae66f1e63688",
            "8b88ecf237964f2a8700147e6b03bc1f",
            "5714b7bf034447beab5c2f816e172f18",
            "e041969bd6b646c2ac6937c15cd7736c",
            "34ca139f7f97450fac65e0f234bde9d1",
            "eb30341b854543a5938a2e2ebc9eb636",
            "b625fb6fe0dc483f99676ebf626ad6a4",
            "41cd1ea622d647f49c065a45fcdc4bbc",
            "dcaf98196c9e4ea8829688d01e808c7b",
            "a717ff409ceb441b9fd416d2431120fe",
            "a141d9b5a6f84fb4b385251b4cfc4c48",
            "c7bf967352824648a0f4cff9ba5d3eb8",
            "136e2f58ea6c4bcabff9bea03027e313",
            "0bd99dfaf579489ab797157171fb5791",
            "b4d7dc8eb9684740b95ee9a65c977eb4",
            "3ceb651d0c13469bbd79feec6a9b2d25",
            "7b9e134276074e0196216c1caa91c12a",
            "7bb5692804124b0e9a01e981143f0d04",
            "a68bb9ece1b94a8d8c8f210342b0a6ef",
            "e570c93e216e4280aeda4cbcef5aa4d5",
            "9d1562d56e6449bc8e4631cdc788d5a9",
            "260240d7033748d2a407aaa5286a01ea",
            "6a5cd25a06964050937ff7b770834e2d",
            "90ef5a63c94a4a65ae7e99c7baece065",
            "85078bfc7e1048b4930eee89425b7f4a",
            "54b9e4d8a90047beba5db0cc940ef13a",
            "7e8697df4fb74a81a0be455eb3afc812",
            "58033e3b09924e27abe92dc390291256",
            "4ac1cdd9e5244416b60c7a38d0ef32d2",
            "b7634c24ce8a487f8f14264a78143988",
            "ebba4e7f69cb4f21b1e7784ccb9abfe5",
            "62972f5fa2e8481ab5e75ee206f80ce4",
            "cf40819370724952b00936fa2f498fa3",
            "50ca8d780ed44fd4b2cb5a4efe4f81c1",
            "27b132bca31f475eb9b51d005cdaf8f0",
            "0fb582c1e72144eebbcd145a2c8698e1",
            "c4ebe1f9cc21496bac05c423cc7e052c",
            "d92a2248197d4d44bff42e5921d7922b",
            "74d1e1901b1c4e899ccf246a7e9fc3d6",
            "739c9a9987944fc39a5c4aa293a41946",
            "3c3bea5bd7264cf18725ebc46f8585cc",
            "0c369554efe745c8ad851a48c8c36190",
            "b96a85bdd50c4ce896290586d1f7d8ee"
          ]
        }
      },
      "source": [
        "RUN_NAME = 'DeepPavlov_mul-SBERT'\n",
        "with open('data/label_weights.pkl', 'rb') as f:\n",
        "        class_weights = pickle.load(f)\n",
        "config = config.get_config('DeepPavlov_mul-SBERT/', num_classes=len(class_weights), weigths=list(class_weights.values()), batch_size=12)\n",
        "model = train.run_training(ModelClass, config, run_name=RUN_NAME)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "No environment variable for node rank defined. Set as 0.\n",
            "CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "660d41e34e5a4be8b4c60ed9467919f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "082ec0069a8449c4956e51449c0fc3c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1db1cadefdf4befaeb7633123a085e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=24.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTokenizing...:   0%|          | 0/215054 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenizing...: 100%|██████████| 215054/215054 [04:13<00:00, 847.88it/s]\n",
            "Tokenizing...: 100%|██████████| 71685/71685 [01:33<00:00, 765.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/sirily/ODS_QA\" target=\"_blank\">https://app.wandb.ai/sirily/ODS_QA</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/sirily/ODS_QA/runs/3d8rtrp5\" target=\"_blank\">https://app.wandb.ai/sirily/ODS_QA/runs/3d8rtrp5</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.1 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\n",
            "    | Name                                             | Type              | Params\n",
            "-----------------------------------------------------------------------------------\n",
            "0   | bert                                             | BertModel         | 177 M \n",
            "1   | bert.embeddings                                  | BertEmbeddings    | 92 M  \n",
            "2   | bert.embeddings.word_embeddings                  | Embedding         | 91 M  \n",
            "3   | bert.embeddings.position_embeddings              | Embedding         | 393 K \n",
            "4   | bert.embeddings.token_type_embeddings            | Embedding         | 1 K   \n",
            "5   | bert.embeddings.LayerNorm                        | LayerNorm         | 1 K   \n",
            "6   | bert.embeddings.dropout                          | Dropout           | 0     \n",
            "7   | bert.encoder                                     | BertEncoder       | 85 M  \n",
            "8   | bert.encoder.layer                               | ModuleList        | 85 M  \n",
            "9   | bert.encoder.layer.0                             | BertLayer         | 7 M   \n",
            "10  | bert.encoder.layer.0.attention                   | BertAttention     | 2 M   \n",
            "11  | bert.encoder.layer.0.attention.self              | BertSelfAttention | 1 M   \n",
            "12  | bert.encoder.layer.0.attention.self.query        | Linear            | 590 K \n",
            "13  | bert.encoder.layer.0.attention.self.key          | Linear            | 590 K \n",
            "14  | bert.encoder.layer.0.attention.self.value        | Linear            | 590 K \n",
            "15  | bert.encoder.layer.0.attention.self.dropout      | Dropout           | 0     \n",
            "16  | bert.encoder.layer.0.attention.output            | BertSelfOutput    | 592 K \n",
            "17  | bert.encoder.layer.0.attention.output.dense      | Linear            | 590 K \n",
            "18  | bert.encoder.layer.0.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "19  | bert.encoder.layer.0.attention.output.dropout    | Dropout           | 0     \n",
            "20  | bert.encoder.layer.0.intermediate                | BertIntermediate  | 2 M   \n",
            "21  | bert.encoder.layer.0.intermediate.dense          | Linear            | 2 M   \n",
            "22  | bert.encoder.layer.0.output                      | BertOutput        | 2 M   \n",
            "23  | bert.encoder.layer.0.output.dense                | Linear            | 2 M   \n",
            "24  | bert.encoder.layer.0.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "25  | bert.encoder.layer.0.output.dropout              | Dropout           | 0     \n",
            "26  | bert.encoder.layer.1                             | BertLayer         | 7 M   \n",
            "27  | bert.encoder.layer.1.attention                   | BertAttention     | 2 M   \n",
            "28  | bert.encoder.layer.1.attention.self              | BertSelfAttention | 1 M   \n",
            "29  | bert.encoder.layer.1.attention.self.query        | Linear            | 590 K \n",
            "30  | bert.encoder.layer.1.attention.self.key          | Linear            | 590 K \n",
            "31  | bert.encoder.layer.1.attention.self.value        | Linear            | 590 K \n",
            "32  | bert.encoder.layer.1.attention.self.dropout      | Dropout           | 0     \n",
            "33  | bert.encoder.layer.1.attention.output            | BertSelfOutput    | 592 K \n",
            "34  | bert.encoder.layer.1.attention.output.dense      | Linear            | 590 K \n",
            "35  | bert.encoder.layer.1.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "36  | bert.encoder.layer.1.attention.output.dropout    | Dropout           | 0     \n",
            "37  | bert.encoder.layer.1.intermediate                | BertIntermediate  | 2 M   \n",
            "38  | bert.encoder.layer.1.intermediate.dense          | Linear            | 2 M   \n",
            "39  | bert.encoder.layer.1.output                      | BertOutput        | 2 M   \n",
            "40  | bert.encoder.layer.1.output.dense                | Linear            | 2 M   \n",
            "41  | bert.encoder.layer.1.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "42  | bert.encoder.layer.1.output.dropout              | Dropout           | 0     \n",
            "43  | bert.encoder.layer.2                             | BertLayer         | 7 M   \n",
            "44  | bert.encoder.layer.2.attention                   | BertAttention     | 2 M   \n",
            "45  | bert.encoder.layer.2.attention.self              | BertSelfAttention | 1 M   \n",
            "46  | bert.encoder.layer.2.attention.self.query        | Linear            | 590 K \n",
            "47  | bert.encoder.layer.2.attention.self.key          | Linear            | 590 K \n",
            "48  | bert.encoder.layer.2.attention.self.value        | Linear            | 590 K \n",
            "49  | bert.encoder.layer.2.attention.self.dropout      | Dropout           | 0     \n",
            "50  | bert.encoder.layer.2.attention.output            | BertSelfOutput    | 592 K \n",
            "51  | bert.encoder.layer.2.attention.output.dense      | Linear            | 590 K \n",
            "52  | bert.encoder.layer.2.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "53  | bert.encoder.layer.2.attention.output.dropout    | Dropout           | 0     \n",
            "54  | bert.encoder.layer.2.intermediate                | BertIntermediate  | 2 M   \n",
            "55  | bert.encoder.layer.2.intermediate.dense          | Linear            | 2 M   \n",
            "56  | bert.encoder.layer.2.output                      | BertOutput        | 2 M   \n",
            "57  | bert.encoder.layer.2.output.dense                | Linear            | 2 M   \n",
            "58  | bert.encoder.layer.2.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "59  | bert.encoder.layer.2.output.dropout              | Dropout           | 0     \n",
            "60  | bert.encoder.layer.3                             | BertLayer         | 7 M   \n",
            "61  | bert.encoder.layer.3.attention                   | BertAttention     | 2 M   \n",
            "62  | bert.encoder.layer.3.attention.self              | BertSelfAttention | 1 M   \n",
            "63  | bert.encoder.layer.3.attention.self.query        | Linear            | 590 K \n",
            "64  | bert.encoder.layer.3.attention.self.key          | Linear            | 590 K \n",
            "65  | bert.encoder.layer.3.attention.self.value        | Linear            | 590 K \n",
            "66  | bert.encoder.layer.3.attention.self.dropout      | Dropout           | 0     \n",
            "67  | bert.encoder.layer.3.attention.output            | BertSelfOutput    | 592 K \n",
            "68  | bert.encoder.layer.3.attention.output.dense      | Linear            | 590 K \n",
            "69  | bert.encoder.layer.3.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "70  | bert.encoder.layer.3.attention.output.dropout    | Dropout           | 0     \n",
            "71  | bert.encoder.layer.3.intermediate                | BertIntermediate  | 2 M   \n",
            "72  | bert.encoder.layer.3.intermediate.dense          | Linear            | 2 M   \n",
            "73  | bert.encoder.layer.3.output                      | BertOutput        | 2 M   \n",
            "74  | bert.encoder.layer.3.output.dense                | Linear            | 2 M   \n",
            "75  | bert.encoder.layer.3.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "76  | bert.encoder.layer.3.output.dropout              | Dropout           | 0     \n",
            "77  | bert.encoder.layer.4                             | BertLayer         | 7 M   \n",
            "78  | bert.encoder.layer.4.attention                   | BertAttention     | 2 M   \n",
            "79  | bert.encoder.layer.4.attention.self              | BertSelfAttention | 1 M   \n",
            "80  | bert.encoder.layer.4.attention.self.query        | Linear            | 590 K \n",
            "81  | bert.encoder.layer.4.attention.self.key          | Linear            | 590 K \n",
            "82  | bert.encoder.layer.4.attention.self.value        | Linear            | 590 K \n",
            "83  | bert.encoder.layer.4.attention.self.dropout      | Dropout           | 0     \n",
            "84  | bert.encoder.layer.4.attention.output            | BertSelfOutput    | 592 K \n",
            "85  | bert.encoder.layer.4.attention.output.dense      | Linear            | 590 K \n",
            "86  | bert.encoder.layer.4.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "87  | bert.encoder.layer.4.attention.output.dropout    | Dropout           | 0     \n",
            "88  | bert.encoder.layer.4.intermediate                | BertIntermediate  | 2 M   \n",
            "89  | bert.encoder.layer.4.intermediate.dense          | Linear            | 2 M   \n",
            "90  | bert.encoder.layer.4.output                      | BertOutput        | 2 M   \n",
            "91  | bert.encoder.layer.4.output.dense                | Linear            | 2 M   \n",
            "92  | bert.encoder.layer.4.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "93  | bert.encoder.layer.4.output.dropout              | Dropout           | 0     \n",
            "94  | bert.encoder.layer.5                             | BertLayer         | 7 M   \n",
            "95  | bert.encoder.layer.5.attention                   | BertAttention     | 2 M   \n",
            "96  | bert.encoder.layer.5.attention.self              | BertSelfAttention | 1 M   \n",
            "97  | bert.encoder.layer.5.attention.self.query        | Linear            | 590 K \n",
            "98  | bert.encoder.layer.5.attention.self.key          | Linear            | 590 K \n",
            "99  | bert.encoder.layer.5.attention.self.value        | Linear            | 590 K \n",
            "100 | bert.encoder.layer.5.attention.self.dropout      | Dropout           | 0     \n",
            "101 | bert.encoder.layer.5.attention.output            | BertSelfOutput    | 592 K \n",
            "102 | bert.encoder.layer.5.attention.output.dense      | Linear            | 590 K \n",
            "103 | bert.encoder.layer.5.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "104 | bert.encoder.layer.5.attention.output.dropout    | Dropout           | 0     \n",
            "105 | bert.encoder.layer.5.intermediate                | BertIntermediate  | 2 M   \n",
            "106 | bert.encoder.layer.5.intermediate.dense          | Linear            | 2 M   \n",
            "107 | bert.encoder.layer.5.output                      | BertOutput        | 2 M   \n",
            "108 | bert.encoder.layer.5.output.dense                | Linear            | 2 M   \n",
            "109 | bert.encoder.layer.5.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "110 | bert.encoder.layer.5.output.dropout              | Dropout           | 0     \n",
            "111 | bert.encoder.layer.6                             | BertLayer         | 7 M   \n",
            "112 | bert.encoder.layer.6.attention                   | BertAttention     | 2 M   \n",
            "113 | bert.encoder.layer.6.attention.self              | BertSelfAttention | 1 M   \n",
            "114 | bert.encoder.layer.6.attention.self.query        | Linear            | 590 K \n",
            "115 | bert.encoder.layer.6.attention.self.key          | Linear            | 590 K \n",
            "116 | bert.encoder.layer.6.attention.self.value        | Linear            | 590 K \n",
            "117 | bert.encoder.layer.6.attention.self.dropout      | Dropout           | 0     \n",
            "118 | bert.encoder.layer.6.attention.output            | BertSelfOutput    | 592 K \n",
            "119 | bert.encoder.layer.6.attention.output.dense      | Linear            | 590 K \n",
            "120 | bert.encoder.layer.6.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "121 | bert.encoder.layer.6.attention.output.dropout    | Dropout           | 0     \n",
            "122 | bert.encoder.layer.6.intermediate                | BertIntermediate  | 2 M   \n",
            "123 | bert.encoder.layer.6.intermediate.dense          | Linear            | 2 M   \n",
            "124 | bert.encoder.layer.6.output                      | BertOutput        | 2 M   \n",
            "125 | bert.encoder.layer.6.output.dense                | Linear            | 2 M   \n",
            "126 | bert.encoder.layer.6.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "127 | bert.encoder.layer.6.output.dropout              | Dropout           | 0     \n",
            "128 | bert.encoder.layer.7                             | BertLayer         | 7 M   \n",
            "129 | bert.encoder.layer.7.attention                   | BertAttention     | 2 M   \n",
            "130 | bert.encoder.layer.7.attention.self              | BertSelfAttention | 1 M   \n",
            "131 | bert.encoder.layer.7.attention.self.query        | Linear            | 590 K \n",
            "132 | bert.encoder.layer.7.attention.self.key          | Linear            | 590 K \n",
            "133 | bert.encoder.layer.7.attention.self.value        | Linear            | 590 K \n",
            "134 | bert.encoder.layer.7.attention.self.dropout      | Dropout           | 0     \n",
            "135 | bert.encoder.layer.7.attention.output            | BertSelfOutput    | 592 K \n",
            "136 | bert.encoder.layer.7.attention.output.dense      | Linear            | 590 K \n",
            "137 | bert.encoder.layer.7.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "138 | bert.encoder.layer.7.attention.output.dropout    | Dropout           | 0     \n",
            "139 | bert.encoder.layer.7.intermediate                | BertIntermediate  | 2 M   \n",
            "140 | bert.encoder.layer.7.intermediate.dense          | Linear            | 2 M   \n",
            "141 | bert.encoder.layer.7.output                      | BertOutput        | 2 M   \n",
            "142 | bert.encoder.layer.7.output.dense                | Linear            | 2 M   \n",
            "143 | bert.encoder.layer.7.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "144 | bert.encoder.layer.7.output.dropout              | Dropout           | 0     \n",
            "145 | bert.encoder.layer.8                             | BertLayer         | 7 M   \n",
            "146 | bert.encoder.layer.8.attention                   | BertAttention     | 2 M   \n",
            "147 | bert.encoder.layer.8.attention.self              | BertSelfAttention | 1 M   \n",
            "148 | bert.encoder.layer.8.attention.self.query        | Linear            | 590 K \n",
            "149 | bert.encoder.layer.8.attention.self.key          | Linear            | 590 K \n",
            "150 | bert.encoder.layer.8.attention.self.value        | Linear            | 590 K \n",
            "151 | bert.encoder.layer.8.attention.self.dropout      | Dropout           | 0     \n",
            "152 | bert.encoder.layer.8.attention.output            | BertSelfOutput    | 592 K \n",
            "153 | bert.encoder.layer.8.attention.output.dense      | Linear            | 590 K \n",
            "154 | bert.encoder.layer.8.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "155 | bert.encoder.layer.8.attention.output.dropout    | Dropout           | 0     \n",
            "156 | bert.encoder.layer.8.intermediate                | BertIntermediate  | 2 M   \n",
            "157 | bert.encoder.layer.8.intermediate.dense          | Linear            | 2 M   \n",
            "158 | bert.encoder.layer.8.output                      | BertOutput        | 2 M   \n",
            "159 | bert.encoder.layer.8.output.dense                | Linear            | 2 M   \n",
            "160 | bert.encoder.layer.8.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "161 | bert.encoder.layer.8.output.dropout              | Dropout           | 0     \n",
            "162 | bert.encoder.layer.9                             | BertLayer         | 7 M   \n",
            "163 | bert.encoder.layer.9.attention                   | BertAttention     | 2 M   \n",
            "164 | bert.encoder.layer.9.attention.self              | BertSelfAttention | 1 M   \n",
            "165 | bert.encoder.layer.9.attention.self.query        | Linear            | 590 K \n",
            "166 | bert.encoder.layer.9.attention.self.key          | Linear            | 590 K \n",
            "167 | bert.encoder.layer.9.attention.self.value        | Linear            | 590 K \n",
            "168 | bert.encoder.layer.9.attention.self.dropout      | Dropout           | 0     \n",
            "169 | bert.encoder.layer.9.attention.output            | BertSelfOutput    | 592 K \n",
            "170 | bert.encoder.layer.9.attention.output.dense      | Linear            | 590 K \n",
            "171 | bert.encoder.layer.9.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
            "172 | bert.encoder.layer.9.attention.output.dropout    | Dropout           | 0     \n",
            "173 | bert.encoder.layer.9.intermediate                | BertIntermediate  | 2 M   \n",
            "174 | bert.encoder.layer.9.intermediate.dense          | Linear            | 2 M   \n",
            "175 | bert.encoder.layer.9.output                      | BertOutput        | 2 M   \n",
            "176 | bert.encoder.layer.9.output.dense                | Linear            | 2 M   \n",
            "177 | bert.encoder.layer.9.output.LayerNorm            | LayerNorm         | 1 K   \n",
            "178 | bert.encoder.layer.9.output.dropout              | Dropout           | 0     \n",
            "179 | bert.encoder.layer.10                            | BertLayer         | 7 M   \n",
            "180 | bert.encoder.layer.10.attention                  | BertAttention     | 2 M   \n",
            "181 | bert.encoder.layer.10.attention.self             | BertSelfAttention | 1 M   \n",
            "182 | bert.encoder.layer.10.attention.self.query       | Linear            | 590 K \n",
            "183 | bert.encoder.layer.10.attention.self.key         | Linear            | 590 K \n",
            "184 | bert.encoder.layer.10.attention.self.value       | Linear            | 590 K \n",
            "185 | bert.encoder.layer.10.attention.self.dropout     | Dropout           | 0     \n",
            "186 | bert.encoder.layer.10.attention.output           | BertSelfOutput    | 592 K \n",
            "187 | bert.encoder.layer.10.attention.output.dense     | Linear            | 590 K \n",
            "188 | bert.encoder.layer.10.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
            "189 | bert.encoder.layer.10.attention.output.dropout   | Dropout           | 0     \n",
            "190 | bert.encoder.layer.10.intermediate               | BertIntermediate  | 2 M   \n",
            "191 | bert.encoder.layer.10.intermediate.dense         | Linear            | 2 M   \n",
            "192 | bert.encoder.layer.10.output                     | BertOutput        | 2 M   \n",
            "193 | bert.encoder.layer.10.output.dense               | Linear            | 2 M   \n",
            "194 | bert.encoder.layer.10.output.LayerNorm           | LayerNorm         | 1 K   \n",
            "195 | bert.encoder.layer.10.output.dropout             | Dropout           | 0     \n",
            "196 | bert.encoder.layer.11                            | BertLayer         | 7 M   \n",
            "197 | bert.encoder.layer.11.attention                  | BertAttention     | 2 M   \n",
            "198 | bert.encoder.layer.11.attention.self             | BertSelfAttention | 1 M   \n",
            "199 | bert.encoder.layer.11.attention.self.query       | Linear            | 590 K \n",
            "200 | bert.encoder.layer.11.attention.self.key         | Linear            | 590 K \n",
            "201 | bert.encoder.layer.11.attention.self.value       | Linear            | 590 K \n",
            "202 | bert.encoder.layer.11.attention.self.dropout     | Dropout           | 0     \n",
            "203 | bert.encoder.layer.11.attention.output           | BertSelfOutput    | 592 K \n",
            "204 | bert.encoder.layer.11.attention.output.dense     | Linear            | 590 K \n",
            "205 | bert.encoder.layer.11.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
            "206 | bert.encoder.layer.11.attention.output.dropout   | Dropout           | 0     \n",
            "207 | bert.encoder.layer.11.intermediate               | BertIntermediate  | 2 M   \n",
            "208 | bert.encoder.layer.11.intermediate.dense         | Linear            | 2 M   \n",
            "209 | bert.encoder.layer.11.output                     | BertOutput        | 2 M   \n",
            "210 | bert.encoder.layer.11.output.dense               | Linear            | 2 M   \n",
            "211 | bert.encoder.layer.11.output.LayerNorm           | LayerNorm         | 1 K   \n",
            "212 | bert.encoder.layer.11.output.dropout             | Dropout           | 0     \n",
            "213 | bert.pooler                                      | BertPooler        | 590 K \n",
            "214 | bert.pooler.dense                                | Linear            | 590 K \n",
            "215 | bert.pooler.activation                           | Tanh              | 0     \n",
            "216 | drop                                             | Dropout           | 0     \n",
            "217 | lin                                              | Linear            | 60 K  \n",
            "218 | soft                                             | Softmax           | 0     \n",
            "219 | loss_fn                                          | CrossEntropyLoss  | 0     \n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e041969bd6b646c2ac6937c15cd7736c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7bf967352824648a0f4cff9ba5d3eb8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e570c93e216e4280aeda4cbcef5aa4d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53765 < 59738; dropping {'val_epoch_loss': 0.4178321063518524, 'val_epoch_auc': 0.9896167650627128, 'epoch': 2}.\n",
            "\n",
            "Epoch 00002: val_epoch_auc reached 0.98962 (best 0.98962), saving model to drive/My Drive/Colab Notebooks/checkpoints/DeepPavlov_mul-SBERT_epoch=2-val_epoch_auc=0.99.ckpt as top 1\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53766 < 59738; dropping {'train_epoch_loss': 0.4468632936477661, 'epoch': 2}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53766 < 59738; dropping {'train_loss': 0.10110193490982056, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53776 < 59738; dropping {'train_loss': 0.5067437291145325, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53786 < 59738; dropping {'train_loss': 1.5799447298049927, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53796 < 59738; dropping {'train_loss': 0.06698349863290787, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53806 < 59738; dropping {'train_loss': 0.07121188938617706, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53816 < 59738; dropping {'train_loss': 0.4894542992115021, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53826 < 59738; dropping {'train_loss': 0.05246661230921745, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53836 < 59738; dropping {'train_loss': 0.05347798019647598, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53846 < 59738; dropping {'train_loss': 0.3027859926223755, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53856 < 59738; dropping {'train_loss': 0.7212586402893066, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53866 < 59738; dropping {'train_loss': 0.10464625060558319, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53876 < 59738; dropping {'train_loss': 0.04799433797597885, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53886 < 59738; dropping {'train_loss': 0.005990650504827499, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53896 < 59738; dropping {'train_loss': 0.047341298311948776, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53906 < 59738; dropping {'train_loss': 0.0790480449795723, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53916 < 59738; dropping {'train_loss': 0.4500744044780731, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53926 < 59738; dropping {'train_loss': 0.2777060866355896, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53936 < 59738; dropping {'train_loss': 0.32243749499320984, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53946 < 59738; dropping {'train_loss': 0.1504565179347992, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53956 < 59738; dropping {'train_loss': 0.0452309176325798, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53966 < 59738; dropping {'train_loss': 0.04579290375113487, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53976 < 59738; dropping {'train_loss': 0.13576415181159973, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53986 < 59738; dropping {'train_loss': 0.04331101477146149, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 53996 < 59738; dropping {'train_loss': 0.37323522567749023, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54006 < 59738; dropping {'train_loss': 0.22887785732746124, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54016 < 59738; dropping {'train_loss': 0.048384010791778564, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54026 < 59738; dropping {'train_loss': 0.4748193621635437, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54036 < 59738; dropping {'train_loss': 0.13201066851615906, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54046 < 59738; dropping {'train_loss': 0.17532671988010406, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54056 < 59738; dropping {'train_loss': 0.8378010392189026, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54066 < 59738; dropping {'train_loss': 0.13561639189720154, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54076 < 59738; dropping {'train_loss': 0.39035147428512573, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54086 < 59738; dropping {'train_loss': 0.2507830262184143, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54096 < 59738; dropping {'train_loss': 0.1735200583934784, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54106 < 59738; dropping {'train_loss': 0.036155760288238525, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54116 < 59738; dropping {'train_loss': 0.2270374894142151, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54126 < 59738; dropping {'train_loss': 0.11285441368818283, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54136 < 59738; dropping {'train_loss': 0.11881733685731888, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54146 < 59738; dropping {'train_loss': 0.14666028320789337, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54156 < 59738; dropping {'train_loss': 0.16638009250164032, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54166 < 59738; dropping {'train_loss': 0.07998140156269073, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54176 < 59738; dropping {'train_loss': 0.8011690378189087, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54186 < 59738; dropping {'train_loss': 0.9240903258323669, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54196 < 59738; dropping {'train_loss': 0.3994907736778259, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54206 < 59738; dropping {'train_loss': 0.1366031914949417, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54216 < 59738; dropping {'train_loss': 0.06308719515800476, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54226 < 59738; dropping {'train_loss': 0.08308619260787964, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54236 < 59738; dropping {'train_loss': 0.24888156354427338, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54246 < 59738; dropping {'train_loss': 0.3466912806034088, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54256 < 59738; dropping {'train_loss': 0.4736434817314148, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54266 < 59738; dropping {'train_loss': 0.08231057226657867, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54276 < 59738; dropping {'train_loss': 0.5725562572479248, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54286 < 59738; dropping {'train_loss': 0.1241910457611084, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54296 < 59738; dropping {'train_loss': 1.4138145446777344, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54306 < 59738; dropping {'train_loss': 0.023735515773296356, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54316 < 59738; dropping {'train_loss': 0.06867993623018265, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54326 < 59738; dropping {'train_loss': 0.12386448681354523, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54336 < 59738; dropping {'train_loss': 0.6637356877326965, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54346 < 59738; dropping {'train_loss': 0.022351330146193504, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54356 < 59738; dropping {'train_loss': 0.19624817371368408, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54366 < 59738; dropping {'train_loss': 0.8181541562080383, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54376 < 59738; dropping {'train_loss': 0.538276195526123, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54386 < 59738; dropping {'train_loss': 0.07654307782649994, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54396 < 59738; dropping {'train_loss': 0.3416585326194763, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54406 < 59738; dropping {'train_loss': 0.3108295202255249, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54416 < 59738; dropping {'train_loss': 0.05378390848636627, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54426 < 59738; dropping {'train_loss': 0.11527164280414581, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54436 < 59738; dropping {'train_loss': 0.2175980806350708, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54446 < 59738; dropping {'train_loss': 0.31057897210121155, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54456 < 59738; dropping {'train_loss': 0.016946349292993546, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54466 < 59738; dropping {'train_loss': 0.1600562483072281, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54476 < 59738; dropping {'train_loss': 0.2677478790283203, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54486 < 59738; dropping {'train_loss': 0.43894171714782715, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54496 < 59738; dropping {'train_loss': 0.010104893706738949, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54506 < 59738; dropping {'train_loss': 1.0878571271896362, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54516 < 59738; dropping {'train_loss': 0.2755849361419678, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54526 < 59738; dropping {'train_loss': 0.06306623667478561, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54536 < 59738; dropping {'train_loss': 0.08877434581518173, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54546 < 59738; dropping {'train_loss': 1.295605182647705, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54556 < 59738; dropping {'train_loss': 0.07744284719228745, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54566 < 59738; dropping {'train_loss': 0.2947506904602051, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54576 < 59738; dropping {'train_loss': 0.09682746976613998, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54586 < 59738; dropping {'train_loss': 0.09129799902439117, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54596 < 59738; dropping {'train_loss': 0.25144463777542114, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54606 < 59738; dropping {'train_loss': 0.04743180051445961, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54616 < 59738; dropping {'train_loss': 0.26874539256095886, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54626 < 59738; dropping {'train_loss': 0.20689566433429718, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54636 < 59738; dropping {'train_loss': 0.046758923679590225, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54646 < 59738; dropping {'train_loss': 0.1707141399383545, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54656 < 59738; dropping {'train_loss': 3.4018118381500244, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54666 < 59738; dropping {'train_loss': 0.08687978237867355, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54676 < 59738; dropping {'train_loss': 0.028080366551876068, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54686 < 59738; dropping {'train_loss': 0.05764453858137131, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54696 < 59738; dropping {'train_loss': 0.05386509373784065, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54706 < 59738; dropping {'train_loss': 0.539360523223877, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54716 < 59738; dropping {'train_loss': 0.02985478937625885, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54726 < 59738; dropping {'train_loss': 0.43493297696113586, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54736 < 59738; dropping {'train_loss': 0.8803759813308716, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54746 < 59738; dropping {'train_loss': 0.07969681918621063, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54756 < 59738; dropping {'train_loss': 0.1322057694196701, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54766 < 59738; dropping {'train_loss': 0.20134983956813812, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54776 < 59738; dropping {'train_loss': 0.09262335300445557, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54786 < 59738; dropping {'train_loss': 0.06339181959629059, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54796 < 59738; dropping {'train_loss': 0.18470247089862823, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54806 < 59738; dropping {'train_loss': 0.047413669526576996, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54816 < 59738; dropping {'train_loss': 0.5183176398277283, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54826 < 59738; dropping {'train_loss': 0.2720937132835388, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54836 < 59738; dropping {'train_loss': 0.05177828297019005, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54846 < 59738; dropping {'train_loss': 0.18014733493328094, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54856 < 59738; dropping {'train_loss': 0.12848153710365295, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54866 < 59738; dropping {'train_loss': 0.05671795457601547, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54876 < 59738; dropping {'train_loss': 0.4000473916530609, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54886 < 59738; dropping {'train_loss': 0.15540428459644318, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54896 < 59738; dropping {'train_loss': 1.6155297756195068, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54906 < 59738; dropping {'train_loss': 0.03263689577579498, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54916 < 59738; dropping {'train_loss': 0.05978700518608093, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54926 < 59738; dropping {'train_loss': 0.03347334638237953, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54936 < 59738; dropping {'train_loss': 0.45997631549835205, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54946 < 59738; dropping {'train_loss': 0.02546272799372673, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54956 < 59738; dropping {'train_loss': 0.0679004117846489, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54966 < 59738; dropping {'train_loss': 0.24212239682674408, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54976 < 59738; dropping {'train_loss': 0.3631962239742279, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54986 < 59738; dropping {'train_loss': 0.032555077224969864, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 54996 < 59738; dropping {'train_loss': 0.461076945066452, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55006 < 59738; dropping {'train_loss': 0.16931472718715668, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55016 < 59738; dropping {'train_loss': 0.6725211143493652, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55026 < 59738; dropping {'train_loss': 0.2327294945716858, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55036 < 59738; dropping {'train_loss': 0.02089623361825943, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55046 < 59738; dropping {'train_loss': 0.10987034440040588, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55056 < 59738; dropping {'train_loss': 0.05027434229850769, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55066 < 59738; dropping {'train_loss': 0.1774928718805313, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55076 < 59738; dropping {'train_loss': 0.12562806904315948, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55086 < 59738; dropping {'train_loss': 0.06454063951969147, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55096 < 59738; dropping {'train_loss': 0.8461337089538574, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55106 < 59738; dropping {'train_loss': 0.6043046712875366, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55116 < 59738; dropping {'train_loss': 0.05571246147155762, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55126 < 59738; dropping {'train_loss': 0.4680515229701996, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55136 < 59738; dropping {'train_loss': 0.2369648963212967, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55146 < 59738; dropping {'train_loss': 0.09412876516580582, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55156 < 59738; dropping {'train_loss': 0.1642400175333023, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55166 < 59738; dropping {'train_loss': 1.7899926900863647, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55176 < 59738; dropping {'train_loss': 0.05239732190966606, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55186 < 59738; dropping {'train_loss': 0.030026709660887718, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55196 < 59738; dropping {'train_loss': 1.0897397994995117, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55206 < 59738; dropping {'train_loss': 0.2693350911140442, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55216 < 59738; dropping {'train_loss': 0.15690715610980988, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55226 < 59738; dropping {'train_loss': 0.15640117228031158, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55236 < 59738; dropping {'train_loss': 0.017007311806082726, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55246 < 59738; dropping {'train_loss': 0.7186169028282166, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55256 < 59738; dropping {'train_loss': 0.23996633291244507, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55266 < 59738; dropping {'train_loss': 0.08601213246583939, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55276 < 59738; dropping {'train_loss': 0.1529957354068756, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55286 < 59738; dropping {'train_loss': 0.028294213116168976, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55296 < 59738; dropping {'train_loss': 0.26434946060180664, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55306 < 59738; dropping {'train_loss': 0.452210396528244, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55316 < 59738; dropping {'train_loss': 0.3147237300872803, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55326 < 59738; dropping {'train_loss': 0.11802248656749725, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55336 < 59738; dropping {'train_loss': 0.752597987651825, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55346 < 59738; dropping {'train_loss': 0.05372799187898636, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55356 < 59738; dropping {'train_loss': 0.07826600968837738, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55366 < 59738; dropping {'train_loss': 0.18989822268486023, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55376 < 59738; dropping {'train_loss': 0.026067471131682396, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55386 < 59738; dropping {'train_loss': 0.6644117832183838, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55396 < 59738; dropping {'train_loss': 0.06549891084432602, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55406 < 59738; dropping {'train_loss': 0.12587891519069672, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55416 < 59738; dropping {'train_loss': 0.11911960691213608, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55426 < 59738; dropping {'train_loss': 0.09785187244415283, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55436 < 59738; dropping {'train_loss': 0.6383005976676941, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55446 < 59738; dropping {'train_loss': 0.30925247073173523, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55456 < 59738; dropping {'train_loss': 0.41504937410354614, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55466 < 59738; dropping {'train_loss': 1.9287775754928589, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55476 < 59738; dropping {'train_loss': 0.03447912633419037, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55486 < 59738; dropping {'train_loss': 0.14877554774284363, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55496 < 59738; dropping {'train_loss': 0.3891265392303467, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55506 < 59738; dropping {'train_loss': 0.18448121845722198, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55516 < 59738; dropping {'train_loss': 1.216609239578247, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55526 < 59738; dropping {'train_loss': 0.7264911532402039, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55536 < 59738; dropping {'train_loss': 0.07740454375743866, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55546 < 59738; dropping {'train_loss': 0.2771182954311371, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55556 < 59738; dropping {'train_loss': 0.36684450507164, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55566 < 59738; dropping {'train_loss': 0.06465575844049454, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55576 < 59738; dropping {'train_loss': 1.902698278427124, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55586 < 59738; dropping {'train_loss': 0.811614990234375, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55596 < 59738; dropping {'train_loss': 0.14048698544502258, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55606 < 59738; dropping {'train_loss': 1.5136278867721558, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55616 < 59738; dropping {'train_loss': 0.017771823331713676, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55626 < 59738; dropping {'train_loss': 0.14701561629772186, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55636 < 59738; dropping {'train_loss': 0.17664694786071777, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55646 < 59738; dropping {'train_loss': 0.10964156687259674, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55656 < 59738; dropping {'train_loss': 0.06281326711177826, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55666 < 59738; dropping {'train_loss': 0.12777864933013916, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55676 < 59738; dropping {'train_loss': 0.15496765077114105, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55686 < 59738; dropping {'train_loss': 0.025768117979168892, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55696 < 59738; dropping {'train_loss': 0.04070776700973511, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55706 < 59738; dropping {'train_loss': 0.40804216265678406, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55716 < 59738; dropping {'train_loss': 0.06518996506929398, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55726 < 59738; dropping {'train_loss': 0.04943908378481865, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55736 < 59738; dropping {'train_loss': 0.045873407274484634, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55746 < 59738; dropping {'train_loss': 1.396224021911621, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55756 < 59738; dropping {'train_loss': 0.2585168778896332, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55766 < 59738; dropping {'train_loss': 0.024078940972685814, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55776 < 59738; dropping {'train_loss': 0.04224751144647598, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55786 < 59738; dropping {'train_loss': 0.44689422845840454, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55796 < 59738; dropping {'train_loss': 0.08022509515285492, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55806 < 59738; dropping {'train_loss': 0.04760638251900673, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55816 < 59738; dropping {'train_loss': 0.3997451961040497, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55826 < 59738; dropping {'train_loss': 0.021736882627010345, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55836 < 59738; dropping {'train_loss': 0.16525495052337646, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55846 < 59738; dropping {'train_loss': 0.035712502896785736, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55856 < 59738; dropping {'train_loss': 0.050088535994291306, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55866 < 59738; dropping {'train_loss': 0.3084428906440735, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55876 < 59738; dropping {'train_loss': 0.19606821238994598, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55886 < 59738; dropping {'train_loss': 0.4723213016986847, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55896 < 59738; dropping {'train_loss': 1.8447208404541016, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55906 < 59738; dropping {'train_loss': 0.1978146880865097, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55916 < 59738; dropping {'train_loss': 0.6819653511047363, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55926 < 59738; dropping {'train_loss': 0.09591298550367355, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55936 < 59738; dropping {'train_loss': 0.16884256899356842, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55946 < 59738; dropping {'train_loss': 0.42040225863456726, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55956 < 59738; dropping {'train_loss': 0.12979532778263092, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55966 < 59738; dropping {'train_loss': 0.07927931845188141, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55976 < 59738; dropping {'train_loss': 0.4603119492530823, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55986 < 59738; dropping {'train_loss': 0.407907098531723, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 55996 < 59738; dropping {'train_loss': 0.16713406145572662, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56006 < 59738; dropping {'train_loss': 0.1171092614531517, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56016 < 59738; dropping {'train_loss': 0.14273223280906677, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56026 < 59738; dropping {'train_loss': 0.1175103709101677, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56036 < 59738; dropping {'train_loss': 0.13731789588928223, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56046 < 59738; dropping {'train_loss': 0.45957398414611816, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56056 < 59738; dropping {'train_loss': 0.09910521656274796, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56066 < 59738; dropping {'train_loss': 0.0697404146194458, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56076 < 59738; dropping {'train_loss': 0.09713714569807053, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56086 < 59738; dropping {'train_loss': 0.163075789809227, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56096 < 59738; dropping {'train_loss': 0.08049750328063965, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56106 < 59738; dropping {'train_loss': 0.24914897978305817, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56116 < 59738; dropping {'train_loss': 0.7588850259780884, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56126 < 59738; dropping {'train_loss': 0.037192899733781815, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56136 < 59738; dropping {'train_loss': 0.43332523107528687, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56146 < 59738; dropping {'train_loss': 0.6812138557434082, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56156 < 59738; dropping {'train_loss': 0.08522836118936539, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56166 < 59738; dropping {'train_loss': 0.38130685687065125, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56176 < 59738; dropping {'train_loss': 0.8940618634223938, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56186 < 59738; dropping {'train_loss': 0.1849503070116043, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56196 < 59738; dropping {'train_loss': 0.8256633281707764, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56206 < 59738; dropping {'train_loss': 0.29548001289367676, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56216 < 59738; dropping {'train_loss': 0.044207025319337845, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56226 < 59738; dropping {'train_loss': 0.5735333561897278, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56236 < 59738; dropping {'train_loss': 1.3487385511398315, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56246 < 59738; dropping {'train_loss': 0.06989988684654236, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56256 < 59738; dropping {'train_loss': 0.19249248504638672, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56266 < 59738; dropping {'train_loss': 0.1866307407617569, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56276 < 59738; dropping {'train_loss': 0.13799422979354858, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56286 < 59738; dropping {'train_loss': 0.8301000595092773, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56296 < 59738; dropping {'train_loss': 0.12008078396320343, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56306 < 59738; dropping {'train_loss': 0.14576521515846252, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56316 < 59738; dropping {'train_loss': 0.059593334794044495, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56326 < 59738; dropping {'train_loss': 0.10804280638694763, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56336 < 59738; dropping {'train_loss': 0.42592042684555054, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56346 < 59738; dropping {'train_loss': 0.36591970920562744, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56356 < 59738; dropping {'train_loss': 0.28026139736175537, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56366 < 59738; dropping {'train_loss': 1.05238938331604, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56376 < 59738; dropping {'train_loss': 0.33540675044059753, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56386 < 59738; dropping {'train_loss': 0.11086991429328918, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56396 < 59738; dropping {'train_loss': 0.7399373650550842, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56406 < 59738; dropping {'train_loss': 0.16163158416748047, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56416 < 59738; dropping {'train_loss': 0.21314933896064758, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56426 < 59738; dropping {'train_loss': 0.6909925937652588, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56436 < 59738; dropping {'train_loss': 0.06255494803190231, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56446 < 59738; dropping {'train_loss': 1.0029563903808594, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56456 < 59738; dropping {'train_loss': 0.2380402535200119, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56466 < 59738; dropping {'train_loss': 0.13687901198863983, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56476 < 59738; dropping {'train_loss': 0.06052152067422867, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56486 < 59738; dropping {'train_loss': 0.022093815729022026, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56496 < 59738; dropping {'train_loss': 0.4588093161582947, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56506 < 59738; dropping {'train_loss': 0.04352676123380661, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56516 < 59738; dropping {'train_loss': 1.1684173345565796, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56526 < 59738; dropping {'train_loss': 0.058289311826229095, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56536 < 59738; dropping {'train_loss': 0.3250020444393158, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56546 < 59738; dropping {'train_loss': 0.05167258903384209, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56556 < 59738; dropping {'train_loss': 0.12602543830871582, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56566 < 59738; dropping {'train_loss': 0.08512096107006073, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56576 < 59738; dropping {'train_loss': 1.1714431047439575, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56586 < 59738; dropping {'train_loss': 0.6272855401039124, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56596 < 59738; dropping {'train_loss': 0.19773876667022705, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56606 < 59738; dropping {'train_loss': 0.08834497630596161, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56616 < 59738; dropping {'train_loss': 0.036590006202459335, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56626 < 59738; dropping {'train_loss': 0.041152045130729675, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56636 < 59738; dropping {'train_loss': 0.12662601470947266, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56646 < 59738; dropping {'train_loss': 0.03194272518157959, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56656 < 59738; dropping {'train_loss': 0.5296499133110046, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56666 < 59738; dropping {'train_loss': 0.3352649211883545, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56676 < 59738; dropping {'train_loss': 0.7000153064727783, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56686 < 59738; dropping {'train_loss': 0.08155249804258347, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56696 < 59738; dropping {'train_loss': 0.042514633387327194, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56706 < 59738; dropping {'train_loss': 0.037220150232315063, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56716 < 59738; dropping {'train_loss': 0.20491059124469757, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56726 < 59738; dropping {'train_loss': 0.16908568143844604, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56736 < 59738; dropping {'train_loss': 0.06009078025817871, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56746 < 59738; dropping {'train_loss': 0.1632208526134491, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56756 < 59738; dropping {'train_loss': 0.13326241075992584, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56766 < 59738; dropping {'train_loss': 0.2302590012550354, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56776 < 59738; dropping {'train_loss': 0.546404242515564, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56786 < 59738; dropping {'train_loss': 0.30864259600639343, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56796 < 59738; dropping {'train_loss': 0.08167722821235657, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56806 < 59738; dropping {'train_loss': 0.2759435474872589, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56816 < 59738; dropping {'train_loss': 0.18025949597358704, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56826 < 59738; dropping {'train_loss': 0.5381977558135986, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56836 < 59738; dropping {'train_loss': 0.18647421896457672, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56846 < 59738; dropping {'train_loss': 1.5334129333496094, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56856 < 59738; dropping {'train_loss': 0.09391340613365173, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56866 < 59738; dropping {'train_loss': 0.04526370018720627, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56876 < 59738; dropping {'train_loss': 0.5723612904548645, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56886 < 59738; dropping {'train_loss': 0.34283313155174255, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56896 < 59738; dropping {'train_loss': 0.6308335661888123, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56906 < 59738; dropping {'train_loss': 0.19097737967967987, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56916 < 59738; dropping {'train_loss': 0.1304420679807663, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56926 < 59738; dropping {'train_loss': 0.4239671230316162, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56936 < 59738; dropping {'train_loss': 0.0713379830121994, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56946 < 59738; dropping {'train_loss': 0.056201912462711334, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56956 < 59738; dropping {'train_loss': 0.24157407879829407, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56966 < 59738; dropping {'train_loss': 0.13134801387786865, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56976 < 59738; dropping {'train_loss': 0.07357247918844223, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56986 < 59738; dropping {'train_loss': 0.24437183141708374, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 56996 < 59738; dropping {'train_loss': 0.05543915182352066, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57006 < 59738; dropping {'train_loss': 0.08400364965200424, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57016 < 59738; dropping {'train_loss': 0.10429594665765762, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57026 < 59738; dropping {'train_loss': 0.17469966411590576, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57036 < 59738; dropping {'train_loss': 0.020324137061834335, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57046 < 59738; dropping {'train_loss': 2.3467836380004883, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57056 < 59738; dropping {'train_loss': 0.4417572021484375, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57066 < 59738; dropping {'train_loss': 0.38933223485946655, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57076 < 59738; dropping {'train_loss': 0.24840664863586426, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57086 < 59738; dropping {'train_loss': 0.02213071845471859, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57096 < 59738; dropping {'train_loss': 0.1292407363653183, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57106 < 59738; dropping {'train_loss': 0.5206823348999023, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57116 < 59738; dropping {'train_loss': 0.24912910163402557, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57126 < 59738; dropping {'train_loss': 0.1452513486146927, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57136 < 59738; dropping {'train_loss': 0.43278446793556213, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57146 < 59738; dropping {'train_loss': 0.040797941386699677, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57156 < 59738; dropping {'train_loss': 0.3736364543437958, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57166 < 59738; dropping {'train_loss': 0.5618667602539062, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57176 < 59738; dropping {'train_loss': 0.10319393873214722, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57186 < 59738; dropping {'train_loss': 0.1909905970096588, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57196 < 59738; dropping {'train_loss': 0.4078178107738495, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57206 < 59738; dropping {'train_loss': 0.29497426748275757, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57216 < 59738; dropping {'train_loss': 0.06097668036818504, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57226 < 59738; dropping {'train_loss': 0.05277759209275246, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57236 < 59738; dropping {'train_loss': 0.0648890882730484, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57246 < 59738; dropping {'train_loss': 0.09376160055398941, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57256 < 59738; dropping {'train_loss': 1.5121729373931885, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57266 < 59738; dropping {'train_loss': 0.04023575782775879, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57276 < 59738; dropping {'train_loss': 0.2099035382270813, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57286 < 59738; dropping {'train_loss': 2.688537836074829, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57296 < 59738; dropping {'train_loss': 0.5957006812095642, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57306 < 59738; dropping {'train_loss': 0.2913723587989807, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57316 < 59738; dropping {'train_loss': 1.1607071161270142, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57326 < 59738; dropping {'train_loss': 1.3146013021469116, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57336 < 59738; dropping {'train_loss': 0.13322100043296814, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57346 < 59738; dropping {'train_loss': 0.14638231694698334, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57356 < 59738; dropping {'train_loss': 0.5755103826522827, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57366 < 59738; dropping {'train_loss': 0.5457792282104492, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57376 < 59738; dropping {'train_loss': 0.5112477540969849, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57386 < 59738; dropping {'train_loss': 0.49771374464035034, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57396 < 59738; dropping {'train_loss': 0.3781019449234009, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57406 < 59738; dropping {'train_loss': 0.02699374593794346, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57416 < 59738; dropping {'train_loss': 0.7802772521972656, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57426 < 59738; dropping {'train_loss': 0.09511444717645645, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57436 < 59738; dropping {'train_loss': 0.05054696276783943, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57446 < 59738; dropping {'train_loss': 0.6130171418190002, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57456 < 59738; dropping {'train_loss': 0.034472107887268066, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57466 < 59738; dropping {'train_loss': 0.15031668543815613, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57476 < 59738; dropping {'train_loss': 0.07246796786785126, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57486 < 59738; dropping {'train_loss': 0.06269727647304535, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57496 < 59738; dropping {'train_loss': 0.04839320480823517, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57506 < 59738; dropping {'train_loss': 0.276196151971817, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57516 < 59738; dropping {'train_loss': 0.28692370653152466, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57526 < 59738; dropping {'train_loss': 0.1572716385126114, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57536 < 59738; dropping {'train_loss': 0.2760998606681824, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57546 < 59738; dropping {'train_loss': 0.03154776617884636, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57556 < 59738; dropping {'train_loss': 0.23457583785057068, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57566 < 59738; dropping {'train_loss': 0.12973104417324066, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57576 < 59738; dropping {'train_loss': 0.09687598049640656, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57586 < 59738; dropping {'train_loss': 0.5555709600448608, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57596 < 59738; dropping {'train_loss': 0.0671328753232956, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57606 < 59738; dropping {'train_loss': 1.3200933933258057, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57616 < 59738; dropping {'train_loss': 0.7820525765419006, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57626 < 59738; dropping {'train_loss': 0.24732448160648346, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57636 < 59738; dropping {'train_loss': 0.11289369314908981, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57646 < 59738; dropping {'train_loss': 0.32734188437461853, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57656 < 59738; dropping {'train_loss': 0.0953921303153038, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57666 < 59738; dropping {'train_loss': 0.8933643698692322, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57676 < 59738; dropping {'train_loss': 0.22958272695541382, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57686 < 59738; dropping {'train_loss': 0.3479407727718353, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57696 < 59738; dropping {'train_loss': 0.35449087619781494, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57706 < 59738; dropping {'train_loss': 0.1771882027387619, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57716 < 59738; dropping {'train_loss': 0.13747990131378174, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57726 < 59738; dropping {'train_loss': 0.4255795478820801, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57736 < 59738; dropping {'train_loss': 0.056387875229120255, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57746 < 59738; dropping {'train_loss': 0.11387039721012115, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57756 < 59738; dropping {'train_loss': 0.246274933218956, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57766 < 59738; dropping {'train_loss': 0.20765860378742218, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57776 < 59738; dropping {'train_loss': 1.3750147819519043, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57786 < 59738; dropping {'train_loss': 0.2668008804321289, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57796 < 59738; dropping {'train_loss': 0.10006610304117203, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57806 < 59738; dropping {'train_loss': 0.7814621925354004, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57816 < 59738; dropping {'train_loss': 0.24124468863010406, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57826 < 59738; dropping {'train_loss': 0.7744783163070679, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57836 < 59738; dropping {'train_loss': 0.24254697561264038, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57846 < 59738; dropping {'train_loss': 0.09596177190542221, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57856 < 59738; dropping {'train_loss': 0.449393093585968, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57866 < 59738; dropping {'train_loss': 0.15860606729984283, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57876 < 59738; dropping {'train_loss': 0.264735609292984, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57886 < 59738; dropping {'train_loss': 0.3101477026939392, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57896 < 59738; dropping {'train_loss': 0.25665175914764404, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57906 < 59738; dropping {'train_loss': 0.18975508213043213, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57916 < 59738; dropping {'train_loss': 0.09463473409414291, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57926 < 59738; dropping {'train_loss': 0.1207461804151535, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57936 < 59738; dropping {'train_loss': 0.30228444933891296, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57946 < 59738; dropping {'train_loss': 0.008802997879683971, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57956 < 59738; dropping {'train_loss': 0.23587290942668915, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57966 < 59738; dropping {'train_loss': 0.3319796025753021, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57976 < 59738; dropping {'train_loss': 0.1844632625579834, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57986 < 59738; dropping {'train_loss': 0.7490325570106506, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 57996 < 59738; dropping {'train_loss': 0.18289880454540253, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58006 < 59738; dropping {'train_loss': 0.03646131977438927, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58016 < 59738; dropping {'train_loss': 0.26594457030296326, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58026 < 59738; dropping {'train_loss': 0.13952770829200745, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58036 < 59738; dropping {'train_loss': 0.09876816719770432, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58046 < 59738; dropping {'train_loss': 0.12054421752691269, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58056 < 59738; dropping {'train_loss': 0.4461551308631897, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58066 < 59738; dropping {'train_loss': 0.10048294067382812, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58076 < 59738; dropping {'train_loss': 0.40821313858032227, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58086 < 59738; dropping {'train_loss': 0.12230879068374634, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58096 < 59738; dropping {'train_loss': 0.15817667543888092, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58106 < 59738; dropping {'train_loss': 0.04733346775174141, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58116 < 59738; dropping {'train_loss': 0.01809360831975937, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58126 < 59738; dropping {'train_loss': 0.06867275387048721, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58136 < 59738; dropping {'train_loss': 0.09121692180633545, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58146 < 59738; dropping {'train_loss': 0.17647473514080048, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58156 < 59738; dropping {'train_loss': 0.7297363877296448, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58166 < 59738; dropping {'train_loss': 0.14852163195610046, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58176 < 59738; dropping {'train_loss': 0.1264096200466156, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58186 < 59738; dropping {'train_loss': 0.04867098852992058, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58196 < 59738; dropping {'train_loss': 0.09317721426486969, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58206 < 59738; dropping {'train_loss': 0.14229027926921844, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58216 < 59738; dropping {'train_loss': 0.07204113900661469, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58226 < 59738; dropping {'train_loss': 0.19962437450885773, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58236 < 59738; dropping {'train_loss': 0.25756070017814636, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58246 < 59738; dropping {'train_loss': 1.11802077293396, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58256 < 59738; dropping {'train_loss': 0.1533956527709961, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58266 < 59738; dropping {'train_loss': 0.016343090683221817, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58276 < 59738; dropping {'train_loss': 0.0744611993432045, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58286 < 59738; dropping {'train_loss': 0.08461584895849228, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58296 < 59738; dropping {'train_loss': 0.045246388763189316, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58306 < 59738; dropping {'train_loss': 0.17623405158519745, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58316 < 59738; dropping {'train_loss': 2.0758490562438965, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58326 < 59738; dropping {'train_loss': 0.1768120974302292, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58336 < 59738; dropping {'train_loss': 0.5786672234535217, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58346 < 59738; dropping {'train_loss': 0.6258075833320618, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58356 < 59738; dropping {'train_loss': 0.6157328486442566, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58366 < 59738; dropping {'train_loss': 0.6104710102081299, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58376 < 59738; dropping {'train_loss': 0.03378588333725929, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58386 < 59738; dropping {'train_loss': 0.4478674829006195, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58396 < 59738; dropping {'train_loss': 0.0402824804186821, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58406 < 59738; dropping {'train_loss': 0.11287494748830795, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58416 < 59738; dropping {'train_loss': 0.22253182530403137, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58426 < 59738; dropping {'train_loss': 0.10859934985637665, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58436 < 59738; dropping {'train_loss': 2.3851685523986816, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58446 < 59738; dropping {'train_loss': 0.1315365880727768, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58456 < 59738; dropping {'train_loss': 0.49611690640449524, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58466 < 59738; dropping {'train_loss': 4.240622520446777, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58476 < 59738; dropping {'train_loss': 0.2615574896335602, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58486 < 59738; dropping {'train_loss': 0.24655374884605408, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58496 < 59738; dropping {'train_loss': 0.08321132510900497, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58506 < 59738; dropping {'train_loss': 0.1122656837105751, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58516 < 59738; dropping {'train_loss': 0.18298153579235077, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58526 < 59738; dropping {'train_loss': 0.06426186859607697, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58536 < 59738; dropping {'train_loss': 0.24428534507751465, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58546 < 59738; dropping {'train_loss': 0.7679077982902527, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58556 < 59738; dropping {'train_loss': 0.035459984093904495, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58566 < 59738; dropping {'train_loss': 0.06757427006959915, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58576 < 59738; dropping {'train_loss': 0.23996277153491974, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58586 < 59738; dropping {'train_loss': 0.4966491460800171, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58596 < 59738; dropping {'train_loss': 0.8486815690994263, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58606 < 59738; dropping {'train_loss': 0.03087965026497841, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58616 < 59738; dropping {'train_loss': 2.157261848449707, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58626 < 59738; dropping {'train_loss': 2.407332181930542, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58636 < 59738; dropping {'train_loss': 0.20444068312644958, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58646 < 59738; dropping {'train_loss': 0.03545752540230751, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58656 < 59738; dropping {'train_loss': 1.028441309928894, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58666 < 59738; dropping {'train_loss': 0.02150784432888031, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58676 < 59738; dropping {'train_loss': 0.09956863522529602, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58686 < 59738; dropping {'train_loss': 0.3462224304676056, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58696 < 59738; dropping {'train_loss': 0.2131246030330658, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58706 < 59738; dropping {'train_loss': 0.03109828382730484, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58716 < 59738; dropping {'train_loss': 1.3027946949005127, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58726 < 59738; dropping {'train_loss': 0.06348879635334015, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58736 < 59738; dropping {'train_loss': 0.149586021900177, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58746 < 59738; dropping {'train_loss': 0.9771121740341187, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58756 < 59738; dropping {'train_loss': 0.09152133017778397, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58766 < 59738; dropping {'train_loss': 0.11194191873073578, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58776 < 59738; dropping {'train_loss': 0.011108811013400555, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58786 < 59738; dropping {'train_loss': 0.5330430269241333, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58796 < 59738; dropping {'train_loss': 0.3059009611606598, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58806 < 59738; dropping {'train_loss': 0.07923015207052231, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58816 < 59738; dropping {'train_loss': 0.03842458501458168, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58826 < 59738; dropping {'train_loss': 0.9886847734451294, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58836 < 59738; dropping {'train_loss': 0.343353271484375, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58846 < 59738; dropping {'train_loss': 0.5948089361190796, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58856 < 59738; dropping {'train_loss': 0.05058276280760765, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58866 < 59738; dropping {'train_loss': 0.5490735769271851, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58876 < 59738; dropping {'train_loss': 0.056498683989048004, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58886 < 59738; dropping {'train_loss': 0.17825880646705627, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58896 < 59738; dropping {'train_loss': 0.08906443417072296, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58906 < 59738; dropping {'train_loss': 0.4542837142944336, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58916 < 59738; dropping {'train_loss': 0.043345700949430466, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58926 < 59738; dropping {'train_loss': 0.04433851316571236, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58936 < 59738; dropping {'train_loss': 0.10033886879682541, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58946 < 59738; dropping {'train_loss': 0.1819741129875183, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58956 < 59738; dropping {'train_loss': 0.19418714940547943, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58966 < 59738; dropping {'train_loss': 0.09985540807247162, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58976 < 59738; dropping {'train_loss': 0.21441875398159027, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58986 < 59738; dropping {'train_loss': 0.1498333215713501, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 58996 < 59738; dropping {'train_loss': 0.5491898655891418, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59006 < 59738; dropping {'train_loss': 0.23062922060489655, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59016 < 59738; dropping {'train_loss': 0.2496289312839508, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59026 < 59738; dropping {'train_loss': 0.3764723241329193, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59036 < 59738; dropping {'train_loss': 0.12647049129009247, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59046 < 59738; dropping {'train_loss': 0.16505184769630432, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59056 < 59738; dropping {'train_loss': 0.12743441760540009, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59066 < 59738; dropping {'train_loss': 0.2531226873397827, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59076 < 59738; dropping {'train_loss': 0.01967274770140648, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59086 < 59738; dropping {'train_loss': 0.2356678992509842, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59096 < 59738; dropping {'train_loss': 2.59867000579834, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59106 < 59738; dropping {'train_loss': 0.1127663403749466, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59116 < 59738; dropping {'train_loss': 2.5099523067474365, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59126 < 59738; dropping {'train_loss': 0.44942808151245117, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59136 < 59738; dropping {'train_loss': 0.20318038761615753, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59146 < 59738; dropping {'train_loss': 0.01390152145177126, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59156 < 59738; dropping {'train_loss': 0.39843904972076416, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59166 < 59738; dropping {'train_loss': 0.09863827377557755, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59176 < 59738; dropping {'train_loss': 0.08797001093626022, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59186 < 59738; dropping {'train_loss': 0.04819329455494881, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59196 < 59738; dropping {'train_loss': 0.04856332764029503, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59206 < 59738; dropping {'train_loss': 1.2137798070907593, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59216 < 59738; dropping {'train_loss': 0.13836079835891724, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59226 < 59738; dropping {'train_loss': 0.15347400307655334, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59236 < 59738; dropping {'train_loss': 0.0592237152159214, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59246 < 59738; dropping {'train_loss': 0.12081044912338257, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59256 < 59738; dropping {'train_loss': 0.061805881559848785, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59266 < 59738; dropping {'train_loss': 0.1194763258099556, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59276 < 59738; dropping {'train_loss': 0.45319297909736633, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59286 < 59738; dropping {'train_loss': 0.057079628109931946, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59296 < 59738; dropping {'train_loss': 0.06897329539060593, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59306 < 59738; dropping {'train_loss': 0.7760382294654846, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59316 < 59738; dropping {'train_loss': 0.11272408068180084, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59326 < 59738; dropping {'train_loss': 0.1713835448026657, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59336 < 59738; dropping {'train_loss': 0.2824854850769043, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59346 < 59738; dropping {'train_loss': 0.060937780886888504, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59356 < 59738; dropping {'train_loss': 0.5148946642875671, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59366 < 59738; dropping {'train_loss': 0.09972064942121506, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59376 < 59738; dropping {'train_loss': 0.07022985816001892, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59386 < 59738; dropping {'train_loss': 0.3118063509464264, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59396 < 59738; dropping {'train_loss': 0.058120086789131165, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59406 < 59738; dropping {'train_loss': 0.11035963892936707, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59416 < 59738; dropping {'train_loss': 0.28190165758132935, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59426 < 59738; dropping {'train_loss': 1.2779109477996826, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59436 < 59738; dropping {'train_loss': 0.04362601786851883, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59446 < 59738; dropping {'train_loss': 0.07307127118110657, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59456 < 59738; dropping {'train_loss': 0.09353303909301758, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59466 < 59738; dropping {'train_loss': 0.11801633983850479, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59476 < 59738; dropping {'train_loss': 0.03260525315999985, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59486 < 59738; dropping {'train_loss': 0.8809288740158081, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59496 < 59738; dropping {'train_loss': 0.5293934345245361, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59506 < 59738; dropping {'train_loss': 0.09692736715078354, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59516 < 59738; dropping {'train_loss': 0.03345699608325958, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59526 < 59738; dropping {'train_loss': 0.21994712948799133, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59536 < 59738; dropping {'train_loss': 0.03176751360297203, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59546 < 59738; dropping {'train_loss': 0.056210797280073166, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59556 < 59738; dropping {'train_loss': 0.34561336040496826, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59566 < 59738; dropping {'train_loss': 0.48978349566459656, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59576 < 59738; dropping {'train_loss': 0.0851665586233139, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59586 < 59738; dropping {'train_loss': 0.08837651461362839, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59596 < 59738; dropping {'train_loss': 0.19030478596687317, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59606 < 59738; dropping {'train_loss': 0.0845375806093216, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59616 < 59738; dropping {'train_loss': 0.04642103239893913, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59626 < 59738; dropping {'train_loss': 0.15069632232189178, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59636 < 59738; dropping {'train_loss': 0.10580660402774811, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59646 < 59738; dropping {'train_loss': 0.6563760042190552, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59656 < 59738; dropping {'train_loss': 0.6273703575134277, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59666 < 59738; dropping {'train_loss': 0.04984342306852341, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59676 < 59738; dropping {'train_loss': 0.18917059898376465, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59686 < 59738; dropping {'train_loss': 0.4967304468154907, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59696 < 59738; dropping {'train_loss': 0.011102731339633465, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59706 < 59738; dropping {'train_loss': 0.0258253812789917, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59716 < 59738; dropping {'train_loss': 0.13978689908981323, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59726 < 59738; dropping {'train_loss': 0.20092761516571045, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 59736 < 59738; dropping {'train_loss': 0.014977112412452698, 'epoch': 3}.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58033e3b09924e27abe92dc390291256",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71687 < 77660; dropping {'val_epoch_loss': 0.355211466550827, 'val_epoch_auc': 0.9908358153773508, 'epoch': 3}.\n",
            "\n",
            "Epoch 00003: val_epoch_auc reached 0.99084 (best 0.99084), saving model to drive/My Drive/Colab Notebooks/checkpoints/DeepPavlov_mul-SBERT_epoch=3-val_epoch_auc=0.99.ckpt as top 1\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71688 < 77660; dropping {'train_epoch_loss': 0.3583787977695465, 'epoch': 3}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71688 < 77660; dropping {'train_loss': 0.10711627453565598, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71698 < 77660; dropping {'train_loss': 0.17075419425964355, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71708 < 77660; dropping {'train_loss': 0.3007778525352478, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71718 < 77660; dropping {'train_loss': 0.7160540819168091, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71728 < 77660; dropping {'train_loss': 0.26956111192703247, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71738 < 77660; dropping {'train_loss': 0.013466945849359035, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71748 < 77660; dropping {'train_loss': 0.04263324290513992, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71758 < 77660; dropping {'train_loss': 0.4047432541847229, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71768 < 77660; dropping {'train_loss': 0.3789202570915222, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71778 < 77660; dropping {'train_loss': 0.02809368073940277, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71788 < 77660; dropping {'train_loss': 0.08395835757255554, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71798 < 77660; dropping {'train_loss': 0.3446955382823944, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71808 < 77660; dropping {'train_loss': 0.11173295229673386, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71818 < 77660; dropping {'train_loss': 0.0912579894065857, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71828 < 77660; dropping {'train_loss': 0.07329326122999191, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71838 < 77660; dropping {'train_loss': 0.01387130469083786, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71848 < 77660; dropping {'train_loss': 0.34939324855804443, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71858 < 77660; dropping {'train_loss': 0.17680023610591888, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71868 < 77660; dropping {'train_loss': 0.09435312449932098, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71878 < 77660; dropping {'train_loss': 0.05265200510621071, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71888 < 77660; dropping {'train_loss': 0.0076161646284163, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71898 < 77660; dropping {'train_loss': 0.056711889803409576, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71908 < 77660; dropping {'train_loss': 0.10693133622407913, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71918 < 77660; dropping {'train_loss': 0.16364045441150665, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71928 < 77660; dropping {'train_loss': 0.8725596070289612, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71938 < 77660; dropping {'train_loss': 0.026612775400280952, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71948 < 77660; dropping {'train_loss': 0.012301212176680565, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71958 < 77660; dropping {'train_loss': 0.03814958035945892, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71968 < 77660; dropping {'train_loss': 0.1453465074300766, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71978 < 77660; dropping {'train_loss': 0.00680980971083045, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71988 < 77660; dropping {'train_loss': 0.21873588860034943, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 71998 < 77660; dropping {'train_loss': 0.05665890499949455, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72008 < 77660; dropping {'train_loss': 0.17188231647014618, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72018 < 77660; dropping {'train_loss': 0.053624190390110016, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72028 < 77660; dropping {'train_loss': 0.06890369206666946, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72038 < 77660; dropping {'train_loss': 0.03308114409446716, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72048 < 77660; dropping {'train_loss': 0.06476633995771408, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72058 < 77660; dropping {'train_loss': 0.07036498188972473, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72068 < 77660; dropping {'train_loss': 0.154468834400177, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72078 < 77660; dropping {'train_loss': 0.1449458748102188, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72088 < 77660; dropping {'train_loss': 0.5742360949516296, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72098 < 77660; dropping {'train_loss': 0.06977228075265884, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72108 < 77660; dropping {'train_loss': 0.1890324503183365, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72118 < 77660; dropping {'train_loss': 0.11813520640134811, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72128 < 77660; dropping {'train_loss': 0.021543672308325768, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72138 < 77660; dropping {'train_loss': 0.1266206055879593, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72148 < 77660; dropping {'train_loss': 0.056472890079021454, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72158 < 77660; dropping {'train_loss': 0.05341222882270813, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72168 < 77660; dropping {'train_loss': 0.03427262604236603, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72178 < 77660; dropping {'train_loss': 0.2776899039745331, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72188 < 77660; dropping {'train_loss': 0.5298631191253662, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72198 < 77660; dropping {'train_loss': 0.5478098392486572, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72208 < 77660; dropping {'train_loss': 0.019699452444911003, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72218 < 77660; dropping {'train_loss': 0.033367451280355453, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72228 < 77660; dropping {'train_loss': 0.47732776403427124, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72238 < 77660; dropping {'train_loss': 0.024073287844657898, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72248 < 77660; dropping {'train_loss': 0.03522642329335213, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72258 < 77660; dropping {'train_loss': 0.28304025530815125, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72268 < 77660; dropping {'train_loss': 0.11150291562080383, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72278 < 77660; dropping {'train_loss': 0.09537414461374283, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72288 < 77660; dropping {'train_loss': 0.016840727999806404, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72298 < 77660; dropping {'train_loss': 0.1324501484632492, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72308 < 77660; dropping {'train_loss': 0.13958102464675903, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72318 < 77660; dropping {'train_loss': 2.981855630874634, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72328 < 77660; dropping {'train_loss': 0.01230431254953146, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72338 < 77660; dropping {'train_loss': 0.03722906485199928, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72348 < 77660; dropping {'train_loss': 0.14648224413394928, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72358 < 77660; dropping {'train_loss': 0.3822574019432068, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72368 < 77660; dropping {'train_loss': 0.3193298280239105, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72378 < 77660; dropping {'train_loss': 0.3370456099510193, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72388 < 77660; dropping {'train_loss': 0.06551546603441238, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72398 < 77660; dropping {'train_loss': 0.06451504677534103, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72408 < 77660; dropping {'train_loss': 5.077696800231934, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72418 < 77660; dropping {'train_loss': 0.007582985796034336, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72428 < 77660; dropping {'train_loss': 0.4262063801288605, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72438 < 77660; dropping {'train_loss': 0.16374316811561584, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72448 < 77660; dropping {'train_loss': 0.08897291123867035, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72458 < 77660; dropping {'train_loss': 0.756841778755188, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72468 < 77660; dropping {'train_loss': 0.14022421836853027, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72478 < 77660; dropping {'train_loss': 0.17722994089126587, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72488 < 77660; dropping {'train_loss': 0.008478846400976181, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72498 < 77660; dropping {'train_loss': 0.10541769117116928, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72508 < 77660; dropping {'train_loss': 0.10377950221300125, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72518 < 77660; dropping {'train_loss': 0.10382221639156342, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72528 < 77660; dropping {'train_loss': 0.8593987226486206, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72538 < 77660; dropping {'train_loss': 0.0652938112616539, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72548 < 77660; dropping {'train_loss': 0.27697139978408813, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72558 < 77660; dropping {'train_loss': 0.6102627515792847, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72568 < 77660; dropping {'train_loss': 0.23151661455631256, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72578 < 77660; dropping {'train_loss': 3.359745740890503, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72588 < 77660; dropping {'train_loss': 0.12047368288040161, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72598 < 77660; dropping {'train_loss': 0.16639359295368195, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72608 < 77660; dropping {'train_loss': 0.010685231536626816, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72618 < 77660; dropping {'train_loss': 0.3681299686431885, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72628 < 77660; dropping {'train_loss': 0.5741885304450989, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72638 < 77660; dropping {'train_loss': 0.15061116218566895, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72648 < 77660; dropping {'train_loss': 2.2164297103881836, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72658 < 77660; dropping {'train_loss': 0.0689169242978096, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72668 < 77660; dropping {'train_loss': 0.10096277296543121, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72678 < 77660; dropping {'train_loss': 0.2783486545085907, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72688 < 77660; dropping {'train_loss': 0.17355333268642426, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72698 < 77660; dropping {'train_loss': 0.2762618064880371, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72708 < 77660; dropping {'train_loss': 0.034724459052085876, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72718 < 77660; dropping {'train_loss': 0.24479876458644867, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72728 < 77660; dropping {'train_loss': 0.05200419947504997, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72738 < 77660; dropping {'train_loss': 0.033591173589229584, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72748 < 77660; dropping {'train_loss': 0.21747906506061554, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72758 < 77660; dropping {'train_loss': 0.05228735879063606, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72768 < 77660; dropping {'train_loss': 0.10449104011058807, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72778 < 77660; dropping {'train_loss': 0.043879929929971695, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72788 < 77660; dropping {'train_loss': 0.07830741256475449, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72798 < 77660; dropping {'train_loss': 0.19272342324256897, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72808 < 77660; dropping {'train_loss': 0.4021180272102356, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72818 < 77660; dropping {'train_loss': 0.1010475903749466, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72828 < 77660; dropping {'train_loss': 0.4305906593799591, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72838 < 77660; dropping {'train_loss': 0.03861825913190842, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72848 < 77660; dropping {'train_loss': 0.12062457948923111, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72858 < 77660; dropping {'train_loss': 0.09390930831432343, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72868 < 77660; dropping {'train_loss': 0.7635391354560852, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72878 < 77660; dropping {'train_loss': 0.15333281457424164, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72888 < 77660; dropping {'train_loss': 0.5386431217193604, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72898 < 77660; dropping {'train_loss': 0.10201023519039154, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72908 < 77660; dropping {'train_loss': 0.08836691826581955, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72918 < 77660; dropping {'train_loss': 0.02559400536119938, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72928 < 77660; dropping {'train_loss': 0.15970148146152496, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72938 < 77660; dropping {'train_loss': 0.10928193479776382, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72948 < 77660; dropping {'train_loss': 0.051700931042432785, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72958 < 77660; dropping {'train_loss': 0.06678510457277298, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72968 < 77660; dropping {'train_loss': 0.2446272373199463, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72978 < 77660; dropping {'train_loss': 0.012956580147147179, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72988 < 77660; dropping {'train_loss': 0.44073349237442017, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 72998 < 77660; dropping {'train_loss': 0.01670721545815468, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73008 < 77660; dropping {'train_loss': 0.04515082389116287, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73018 < 77660; dropping {'train_loss': 0.6118649244308472, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73028 < 77660; dropping {'train_loss': 0.005264298524707556, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73038 < 77660; dropping {'train_loss': 0.6847497820854187, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73048 < 77660; dropping {'train_loss': 0.017555857077240944, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73058 < 77660; dropping {'train_loss': 0.08369016647338867, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73068 < 77660; dropping {'train_loss': 0.08478215336799622, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73078 < 77660; dropping {'train_loss': 0.1599206179380417, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73088 < 77660; dropping {'train_loss': 0.5554943084716797, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73098 < 77660; dropping {'train_loss': 0.12624117732048035, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73108 < 77660; dropping {'train_loss': 0.2123081386089325, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73118 < 77660; dropping {'train_loss': 0.6133604049682617, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73128 < 77660; dropping {'train_loss': 1.3642810583114624, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73138 < 77660; dropping {'train_loss': 0.14618870615959167, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73148 < 77660; dropping {'train_loss': 0.052445147186517715, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73158 < 77660; dropping {'train_loss': 0.014826720580458641, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73168 < 77660; dropping {'train_loss': 0.07959836721420288, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73178 < 77660; dropping {'train_loss': 0.13678543269634247, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73188 < 77660; dropping {'train_loss': 2.584805727005005, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73198 < 77660; dropping {'train_loss': 0.008066404610872269, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73208 < 77660; dropping {'train_loss': 0.07146007567644119, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73218 < 77660; dropping {'train_loss': 0.103570356965065, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73228 < 77660; dropping {'train_loss': 0.1340874433517456, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73238 < 77660; dropping {'train_loss': 0.013182025402784348, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73248 < 77660; dropping {'train_loss': 0.14393356442451477, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73258 < 77660; dropping {'train_loss': 0.02753479965031147, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73268 < 77660; dropping {'train_loss': 0.08338241279125214, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73278 < 77660; dropping {'train_loss': 0.020136548206210136, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73288 < 77660; dropping {'train_loss': 0.09434221684932709, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73298 < 77660; dropping {'train_loss': 0.059913620352745056, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73308 < 77660; dropping {'train_loss': 0.3672303557395935, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73318 < 77660; dropping {'train_loss': 0.465751051902771, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73328 < 77660; dropping {'train_loss': 4.6736602783203125, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73338 < 77660; dropping {'train_loss': 0.043872855603694916, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73348 < 77660; dropping {'train_loss': 0.48112088441848755, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73358 < 77660; dropping {'train_loss': 0.39090487360954285, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73368 < 77660; dropping {'train_loss': 0.07254133373498917, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73378 < 77660; dropping {'train_loss': 0.189517542719841, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73388 < 77660; dropping {'train_loss': 0.07831625640392303, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73398 < 77660; dropping {'train_loss': 0.013789140619337559, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73408 < 77660; dropping {'train_loss': 0.049255549907684326, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73418 < 77660; dropping {'train_loss': 0.45263826847076416, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73428 < 77660; dropping {'train_loss': 0.08417095243930817, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73438 < 77660; dropping {'train_loss': 0.0790703296661377, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73448 < 77660; dropping {'train_loss': 0.02179591730237007, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73458 < 77660; dropping {'train_loss': 0.32001787424087524, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73468 < 77660; dropping {'train_loss': 0.05064265802502632, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73478 < 77660; dropping {'train_loss': 0.0765102356672287, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73488 < 77660; dropping {'train_loss': 0.13846361637115479, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73498 < 77660; dropping {'train_loss': 0.012075343169271946, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73508 < 77660; dropping {'train_loss': 0.2633470892906189, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73518 < 77660; dropping {'train_loss': 0.11810339987277985, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73528 < 77660; dropping {'train_loss': 0.06957285106182098, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73538 < 77660; dropping {'train_loss': 1.2520887851715088, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73548 < 77660; dropping {'train_loss': 0.2991401255130768, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73558 < 77660; dropping {'train_loss': 0.4806325137615204, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73568 < 77660; dropping {'train_loss': 0.18109160661697388, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73578 < 77660; dropping {'train_loss': 0.04811467230319977, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73588 < 77660; dropping {'train_loss': 0.05854916572570801, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73598 < 77660; dropping {'train_loss': 0.030044877901673317, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73608 < 77660; dropping {'train_loss': 0.30411943793296814, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73618 < 77660; dropping {'train_loss': 0.020551038905978203, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73628 < 77660; dropping {'train_loss': 0.06966053694486618, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73638 < 77660; dropping {'train_loss': 0.396602988243103, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73648 < 77660; dropping {'train_loss': 0.025195766240358353, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73658 < 77660; dropping {'train_loss': 0.053142353892326355, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73668 < 77660; dropping {'train_loss': 0.3528015911579132, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73678 < 77660; dropping {'train_loss': 0.11059948056936264, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73688 < 77660; dropping {'train_loss': 0.046098463237285614, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73698 < 77660; dropping {'train_loss': 0.004232123959809542, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73708 < 77660; dropping {'train_loss': 0.057247959077358246, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73718 < 77660; dropping {'train_loss': 0.07977914065122604, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73728 < 77660; dropping {'train_loss': 0.02982599101960659, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73738 < 77660; dropping {'train_loss': 0.27442002296447754, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73748 < 77660; dropping {'train_loss': 0.0900835245847702, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73758 < 77660; dropping {'train_loss': 0.012032664380967617, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73768 < 77660; dropping {'train_loss': 0.1402168869972229, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73778 < 77660; dropping {'train_loss': 0.07744838297367096, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73788 < 77660; dropping {'train_loss': 0.30023059248924255, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73798 < 77660; dropping {'train_loss': 0.1226499006152153, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73808 < 77660; dropping {'train_loss': 0.6052078604698181, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73818 < 77660; dropping {'train_loss': 0.06835218518972397, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73828 < 77660; dropping {'train_loss': 0.3585987687110901, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73838 < 77660; dropping {'train_loss': 0.03317166119813919, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73848 < 77660; dropping {'train_loss': 0.07672213762998581, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73858 < 77660; dropping {'train_loss': 0.14955277740955353, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73868 < 77660; dropping {'train_loss': 0.004634535405784845, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73878 < 77660; dropping {'train_loss': 0.021474501118063927, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73888 < 77660; dropping {'train_loss': 0.02679925225675106, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73898 < 77660; dropping {'train_loss': 0.17239904403686523, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73908 < 77660; dropping {'train_loss': 1.1188645362854004, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73918 < 77660; dropping {'train_loss': 0.2735603153705597, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73928 < 77660; dropping {'train_loss': 0.16860155761241913, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73938 < 77660; dropping {'train_loss': 0.08403194695711136, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73948 < 77660; dropping {'train_loss': 0.09163679927587509, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73958 < 77660; dropping {'train_loss': 0.4764627516269684, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73968 < 77660; dropping {'train_loss': 0.17549872398376465, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73978 < 77660; dropping {'train_loss': 0.12349145859479904, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73988 < 77660; dropping {'train_loss': 0.04770474135875702, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 73998 < 77660; dropping {'train_loss': 0.013338124379515648, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74008 < 77660; dropping {'train_loss': 0.06732562184333801, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74018 < 77660; dropping {'train_loss': 0.3058669865131378, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74028 < 77660; dropping {'train_loss': 0.10797906666994095, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74038 < 77660; dropping {'train_loss': 2.9797801971435547, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74048 < 77660; dropping {'train_loss': 0.09140852093696594, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74058 < 77660; dropping {'train_loss': 0.05100024864077568, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74068 < 77660; dropping {'train_loss': 0.03517214208841324, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74078 < 77660; dropping {'train_loss': 0.45833075046539307, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74088 < 77660; dropping {'train_loss': 0.011925306171178818, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74098 < 77660; dropping {'train_loss': 0.16319581866264343, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74108 < 77660; dropping {'train_loss': 0.03596514090895653, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74118 < 77660; dropping {'train_loss': 1.0069618225097656, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74128 < 77660; dropping {'train_loss': 0.0953967347741127, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74138 < 77660; dropping {'train_loss': 0.04297158122062683, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74148 < 77660; dropping {'train_loss': 0.15100230276584625, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74158 < 77660; dropping {'train_loss': 0.06676901876926422, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74168 < 77660; dropping {'train_loss': 0.30793997645378113, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74178 < 77660; dropping {'train_loss': 0.07551757246255875, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74188 < 77660; dropping {'train_loss': 0.34021398425102234, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74198 < 77660; dropping {'train_loss': 0.09133468568325043, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74208 < 77660; dropping {'train_loss': 0.23066462576389313, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74218 < 77660; dropping {'train_loss': 0.09187827259302139, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74228 < 77660; dropping {'train_loss': 0.047346167266368866, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74238 < 77660; dropping {'train_loss': 0.026340840384364128, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74248 < 77660; dropping {'train_loss': 0.023129574954509735, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74258 < 77660; dropping {'train_loss': 0.2538512647151947, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74268 < 77660; dropping {'train_loss': 0.005576459690928459, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74278 < 77660; dropping {'train_loss': 0.06937479972839355, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74288 < 77660; dropping {'train_loss': 0.04434511438012123, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74298 < 77660; dropping {'train_loss': 0.04241636022925377, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74308 < 77660; dropping {'train_loss': 0.02087542600929737, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74318 < 77660; dropping {'train_loss': 0.03481701761484146, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74328 < 77660; dropping {'train_loss': 0.07189024984836578, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74338 < 77660; dropping {'train_loss': 0.13151142001152039, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74348 < 77660; dropping {'train_loss': 0.01973106525838375, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74358 < 77660; dropping {'train_loss': 0.3783551752567291, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74368 < 77660; dropping {'train_loss': 0.2704832851886749, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74378 < 77660; dropping {'train_loss': 0.026753993704915047, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74388 < 77660; dropping {'train_loss': 4.340962886810303, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74398 < 77660; dropping {'train_loss': 0.08684726059436798, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74408 < 77660; dropping {'train_loss': 0.41455066204071045, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74418 < 77660; dropping {'train_loss': 0.10787444561719894, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74428 < 77660; dropping {'train_loss': 0.038059353828430176, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74438 < 77660; dropping {'train_loss': 1.749114990234375, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74448 < 77660; dropping {'train_loss': 0.07707991451025009, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74458 < 77660; dropping {'train_loss': 0.032893937081098557, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74468 < 77660; dropping {'train_loss': 0.12977105379104614, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74478 < 77660; dropping {'train_loss': 0.4706612825393677, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74488 < 77660; dropping {'train_loss': 0.030786965042352676, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74498 < 77660; dropping {'train_loss': 0.08415395766496658, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74508 < 77660; dropping {'train_loss': 0.024253888055682182, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74518 < 77660; dropping {'train_loss': 0.7167329788208008, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74528 < 77660; dropping {'train_loss': 0.368283212184906, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74538 < 77660; dropping {'train_loss': 1.0479575395584106, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74548 < 77660; dropping {'train_loss': 0.11652655899524689, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74558 < 77660; dropping {'train_loss': 0.09943968802690506, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74568 < 77660; dropping {'train_loss': 0.1663968712091446, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74578 < 77660; dropping {'train_loss': 0.11163371801376343, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74588 < 77660; dropping {'train_loss': 0.03266110271215439, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74598 < 77660; dropping {'train_loss': 0.263668954372406, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74608 < 77660; dropping {'train_loss': 0.0256803035736084, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74618 < 77660; dropping {'train_loss': 0.04956251382827759, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74628 < 77660; dropping {'train_loss': 0.04640679061412811, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74638 < 77660; dropping {'train_loss': 0.027056308463215828, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74648 < 77660; dropping {'train_loss': 0.237330362200737, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74658 < 77660; dropping {'train_loss': 0.010117040947079659, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74668 < 77660; dropping {'train_loss': 0.14940960705280304, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74678 < 77660; dropping {'train_loss': 0.5863720178604126, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74688 < 77660; dropping {'train_loss': 0.0273749940097332, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74698 < 77660; dropping {'train_loss': 0.02761702798306942, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74708 < 77660; dropping {'train_loss': 0.2655252516269684, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74718 < 77660; dropping {'train_loss': 0.2325398027896881, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74728 < 77660; dropping {'train_loss': 0.15154729783535004, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74738 < 77660; dropping {'train_loss': 0.04179095849394798, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74748 < 77660; dropping {'train_loss': 0.5330946445465088, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74758 < 77660; dropping {'train_loss': 0.12047172337770462, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74768 < 77660; dropping {'train_loss': 0.1448306143283844, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74778 < 77660; dropping {'train_loss': 0.01572663150727749, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74788 < 77660; dropping {'train_loss': 0.10040632635354996, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74798 < 77660; dropping {'train_loss': 0.05616498365998268, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74808 < 77660; dropping {'train_loss': 0.8116567134857178, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74818 < 77660; dropping {'train_loss': 0.09163607656955719, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74828 < 77660; dropping {'train_loss': 0.09202240407466888, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74838 < 77660; dropping {'train_loss': 0.00793349277228117, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74848 < 77660; dropping {'train_loss': 0.6986972689628601, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74858 < 77660; dropping {'train_loss': 0.9660528898239136, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74868 < 77660; dropping {'train_loss': 0.1439039409160614, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74878 < 77660; dropping {'train_loss': 0.019530946388840675, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74888 < 77660; dropping {'train_loss': 0.05118422210216522, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74898 < 77660; dropping {'train_loss': 0.2409237176179886, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74908 < 77660; dropping {'train_loss': 0.6454768180847168, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74918 < 77660; dropping {'train_loss': 0.16341669857501984, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74928 < 77660; dropping {'train_loss': 0.5052890181541443, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74938 < 77660; dropping {'train_loss': 0.659235417842865, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74948 < 77660; dropping {'train_loss': 0.49630123376846313, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74958 < 77660; dropping {'train_loss': 0.09057045727968216, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74968 < 77660; dropping {'train_loss': 0.2204369604587555, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74978 < 77660; dropping {'train_loss': 0.15049272775650024, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74988 < 77660; dropping {'train_loss': 0.18635708093643188, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 74998 < 77660; dropping {'train_loss': 0.09083040803670883, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75008 < 77660; dropping {'train_loss': 0.3632056713104248, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75018 < 77660; dropping {'train_loss': 0.23426251113414764, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75028 < 77660; dropping {'train_loss': 0.013278805650770664, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75038 < 77660; dropping {'train_loss': 0.4043336510658264, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75048 < 77660; dropping {'train_loss': 0.25374534726142883, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75058 < 77660; dropping {'train_loss': 0.20044510066509247, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75068 < 77660; dropping {'train_loss': 0.4659660756587982, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75078 < 77660; dropping {'train_loss': 0.23422560095787048, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75088 < 77660; dropping {'train_loss': 0.04338417947292328, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75098 < 77660; dropping {'train_loss': 0.06650900095701218, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75108 < 77660; dropping {'train_loss': 1.3577216863632202, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75118 < 77660; dropping {'train_loss': 0.7615054845809937, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75128 < 77660; dropping {'train_loss': 0.053304851055145264, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75138 < 77660; dropping {'train_loss': 0.1437079906463623, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75148 < 77660; dropping {'train_loss': 0.39971375465393066, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75158 < 77660; dropping {'train_loss': 0.10614702850580215, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75168 < 77660; dropping {'train_loss': 2.7909843921661377, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75178 < 77660; dropping {'train_loss': 0.03863777592778206, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75188 < 77660; dropping {'train_loss': 0.2341945767402649, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75198 < 77660; dropping {'train_loss': 0.012600325047969818, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75208 < 77660; dropping {'train_loss': 0.18187792599201202, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75218 < 77660; dropping {'train_loss': 0.1470150202512741, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75228 < 77660; dropping {'train_loss': 0.05754091590642929, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75238 < 77660; dropping {'train_loss': 0.2194889783859253, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75248 < 77660; dropping {'train_loss': 0.0580216646194458, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75258 < 77660; dropping {'train_loss': 0.022220192477107048, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75268 < 77660; dropping {'train_loss': 0.21676093339920044, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75278 < 77660; dropping {'train_loss': 0.0049927616491913795, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75288 < 77660; dropping {'train_loss': 0.21885603666305542, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75298 < 77660; dropping {'train_loss': 0.32118332386016846, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75308 < 77660; dropping {'train_loss': 0.4721343517303467, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75318 < 77660; dropping {'train_loss': 0.027000410482287407, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75328 < 77660; dropping {'train_loss': 0.36907026171684265, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75338 < 77660; dropping {'train_loss': 0.17265263199806213, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75348 < 77660; dropping {'train_loss': 0.009888025932013988, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75358 < 77660; dropping {'train_loss': 0.16218265891075134, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75368 < 77660; dropping {'train_loss': 0.09625618159770966, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75378 < 77660; dropping {'train_loss': 0.05581723526120186, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75388 < 77660; dropping {'train_loss': 0.07403451949357986, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75398 < 77660; dropping {'train_loss': 0.013879799284040928, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75408 < 77660; dropping {'train_loss': 0.08107615262269974, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75418 < 77660; dropping {'train_loss': 0.28528136014938354, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75428 < 77660; dropping {'train_loss': 0.3869140148162842, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75438 < 77660; dropping {'train_loss': 0.07065390050411224, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75448 < 77660; dropping {'train_loss': 0.0950106680393219, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75458 < 77660; dropping {'train_loss': 0.023980537429451942, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75468 < 77660; dropping {'train_loss': 0.09901373088359833, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75478 < 77660; dropping {'train_loss': 0.13658912479877472, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75488 < 77660; dropping {'train_loss': 0.07804043591022491, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75498 < 77660; dropping {'train_loss': 0.1327914595603943, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75508 < 77660; dropping {'train_loss': 0.033210720866918564, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75518 < 77660; dropping {'train_loss': 0.2757839560508728, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75528 < 77660; dropping {'train_loss': 0.6313779950141907, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75538 < 77660; dropping {'train_loss': 0.0747610479593277, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75548 < 77660; dropping {'train_loss': 0.07185426354408264, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75558 < 77660; dropping {'train_loss': 0.45991554856300354, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75568 < 77660; dropping {'train_loss': 0.4181140661239624, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75578 < 77660; dropping {'train_loss': 0.06876880675554276, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75588 < 77660; dropping {'train_loss': 0.06694595515727997, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75598 < 77660; dropping {'train_loss': 0.03672417998313904, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75608 < 77660; dropping {'train_loss': 0.20244769752025604, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75618 < 77660; dropping {'train_loss': 0.3966032564640045, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75628 < 77660; dropping {'train_loss': 0.03845915570855141, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75638 < 77660; dropping {'train_loss': 0.023072078824043274, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75648 < 77660; dropping {'train_loss': 0.16637670993804932, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75658 < 77660; dropping {'train_loss': 0.01108961459249258, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75668 < 77660; dropping {'train_loss': 0.36363089084625244, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75678 < 77660; dropping {'train_loss': 0.028853867202997208, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75688 < 77660; dropping {'train_loss': 0.05762946605682373, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75698 < 77660; dropping {'train_loss': 0.01321469247341156, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75708 < 77660; dropping {'train_loss': 0.06216321513056755, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75718 < 77660; dropping {'train_loss': 0.8524235486984253, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75728 < 77660; dropping {'train_loss': 0.26659494638442993, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75738 < 77660; dropping {'train_loss': 0.5210732221603394, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75748 < 77660; dropping {'train_loss': 0.13545623421669006, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75758 < 77660; dropping {'train_loss': 0.08971542119979858, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75768 < 77660; dropping {'train_loss': 0.051562920212745667, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75778 < 77660; dropping {'train_loss': 0.20574186742305756, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75788 < 77660; dropping {'train_loss': 0.2608458697795868, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75798 < 77660; dropping {'train_loss': 0.026004547253251076, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75808 < 77660; dropping {'train_loss': 0.04877696558833122, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75818 < 77660; dropping {'train_loss': 0.01553141139447689, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75828 < 77660; dropping {'train_loss': 0.0973716676235199, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75838 < 77660; dropping {'train_loss': 0.010819661431014538, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75848 < 77660; dropping {'train_loss': 0.44912588596343994, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75858 < 77660; dropping {'train_loss': 0.01181138213723898, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75868 < 77660; dropping {'train_loss': 0.01633429527282715, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75878 < 77660; dropping {'train_loss': 0.3283931016921997, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75888 < 77660; dropping {'train_loss': 0.037280384451150894, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75898 < 77660; dropping {'train_loss': 0.016713561490178108, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75908 < 77660; dropping {'train_loss': 0.5635862946510315, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75918 < 77660; dropping {'train_loss': 0.035050515085458755, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75928 < 77660; dropping {'train_loss': 0.04733841493725777, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75938 < 77660; dropping {'train_loss': 0.04944274574518204, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75948 < 77660; dropping {'train_loss': 0.11726079136133194, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75958 < 77660; dropping {'train_loss': 0.10284775495529175, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75968 < 77660; dropping {'train_loss': 1.130179762840271, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75978 < 77660; dropping {'train_loss': 0.0504298210144043, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75988 < 77660; dropping {'train_loss': 0.34940844774246216, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 75998 < 77660; dropping {'train_loss': 0.17909391224384308, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76008 < 77660; dropping {'train_loss': 0.13883666694164276, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76018 < 77660; dropping {'train_loss': 0.3293006122112274, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76028 < 77660; dropping {'train_loss': 0.7896984219551086, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76038 < 77660; dropping {'train_loss': 0.6756218671798706, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76048 < 77660; dropping {'train_loss': 0.021457215771079063, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76058 < 77660; dropping {'train_loss': 0.18551766872406006, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76068 < 77660; dropping {'train_loss': 0.12914490699768066, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76078 < 77660; dropping {'train_loss': 0.039755307137966156, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76088 < 77660; dropping {'train_loss': 0.13305459916591644, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76098 < 77660; dropping {'train_loss': 0.035433217883110046, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76108 < 77660; dropping {'train_loss': 0.00913308560848236, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76118 < 77660; dropping {'train_loss': 0.8154563307762146, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76128 < 77660; dropping {'train_loss': 0.09493347257375717, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76138 < 77660; dropping {'train_loss': 0.1370718628168106, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76148 < 77660; dropping {'train_loss': 0.8643577694892883, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76158 < 77660; dropping {'train_loss': 1.0132509469985962, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76168 < 77660; dropping {'train_loss': 0.039809055626392365, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76178 < 77660; dropping {'train_loss': 0.14380468428134918, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76188 < 77660; dropping {'train_loss': 0.04537560045719147, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76198 < 77660; dropping {'train_loss': 0.35625773668289185, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76208 < 77660; dropping {'train_loss': 0.006424834951758385, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76218 < 77660; dropping {'train_loss': 0.13026118278503418, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76228 < 77660; dropping {'train_loss': 0.19237762689590454, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76238 < 77660; dropping {'train_loss': 0.32514286041259766, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76248 < 77660; dropping {'train_loss': 0.6985166668891907, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76258 < 77660; dropping {'train_loss': 0.09667564183473587, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76268 < 77660; dropping {'train_loss': 0.11259350925683975, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76278 < 77660; dropping {'train_loss': 0.043450597673654556, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76288 < 77660; dropping {'train_loss': 0.014017105102539062, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76298 < 77660; dropping {'train_loss': 0.27166083455085754, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76308 < 77660; dropping {'train_loss': 0.034113552421331406, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76318 < 77660; dropping {'train_loss': 0.04244709014892578, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76328 < 77660; dropping {'train_loss': 0.029207417741417885, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76338 < 77660; dropping {'train_loss': 0.029856108129024506, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76348 < 77660; dropping {'train_loss': 0.02885606326162815, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76358 < 77660; dropping {'train_loss': 0.5774857997894287, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76368 < 77660; dropping {'train_loss': 0.015713749453425407, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76378 < 77660; dropping {'train_loss': 0.056500695645809174, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76388 < 77660; dropping {'train_loss': 0.09070984274148941, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76398 < 77660; dropping {'train_loss': 0.059082530438899994, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76408 < 77660; dropping {'train_loss': 0.9795671105384827, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76418 < 77660; dropping {'train_loss': 0.5969616174697876, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76428 < 77660; dropping {'train_loss': 0.188155859708786, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76438 < 77660; dropping {'train_loss': 0.18172667920589447, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76448 < 77660; dropping {'train_loss': 0.020656095817685127, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76458 < 77660; dropping {'train_loss': 0.2467373162508011, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76468 < 77660; dropping {'train_loss': 0.06983474642038345, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76478 < 77660; dropping {'train_loss': 0.10917781293392181, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76488 < 77660; dropping {'train_loss': 0.5816826224327087, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76498 < 77660; dropping {'train_loss': 0.01771540939807892, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76508 < 77660; dropping {'train_loss': 0.13175266981124878, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76518 < 77660; dropping {'train_loss': 0.05466466397047043, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76528 < 77660; dropping {'train_loss': 0.021137960255146027, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76538 < 77660; dropping {'train_loss': 0.10509426891803741, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76548 < 77660; dropping {'train_loss': 0.6949502229690552, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76558 < 77660; dropping {'train_loss': 0.0656498372554779, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76568 < 77660; dropping {'train_loss': 0.3856754004955292, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76578 < 77660; dropping {'train_loss': 0.05798196420073509, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76588 < 77660; dropping {'train_loss': 0.4988073706626892, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76598 < 77660; dropping {'train_loss': 0.27076563239097595, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76608 < 77660; dropping {'train_loss': 2.0078189373016357, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76618 < 77660; dropping {'train_loss': 0.46336352825164795, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76628 < 77660; dropping {'train_loss': 0.02001113072037697, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76638 < 77660; dropping {'train_loss': 0.007016378920525312, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76648 < 77660; dropping {'train_loss': 0.018097752705216408, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76658 < 77660; dropping {'train_loss': 0.15228942036628723, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76668 < 77660; dropping {'train_loss': 0.12234165519475937, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76678 < 77660; dropping {'train_loss': 2.4458165168762207, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76688 < 77660; dropping {'train_loss': 0.1689358800649643, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76698 < 77660; dropping {'train_loss': 0.5108742117881775, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76708 < 77660; dropping {'train_loss': 1.3412812948226929, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76718 < 77660; dropping {'train_loss': 0.023826589807868004, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76728 < 77660; dropping {'train_loss': 0.3362726867198944, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76738 < 77660; dropping {'train_loss': 0.42218196392059326, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76748 < 77660; dropping {'train_loss': 0.1907760202884674, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76758 < 77660; dropping {'train_loss': 0.04788589850068092, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76768 < 77660; dropping {'train_loss': 0.26572123169898987, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76778 < 77660; dropping {'train_loss': 0.21632733941078186, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76788 < 77660; dropping {'train_loss': 0.08672171831130981, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76798 < 77660; dropping {'train_loss': 0.29479411244392395, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76808 < 77660; dropping {'train_loss': 0.02005113661289215, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76818 < 77660; dropping {'train_loss': 0.03472492843866348, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76828 < 77660; dropping {'train_loss': 0.11643002927303314, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76838 < 77660; dropping {'train_loss': 0.019563524052500725, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76848 < 77660; dropping {'train_loss': 0.3397108018398285, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76858 < 77660; dropping {'train_loss': 0.07047925144433975, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76868 < 77660; dropping {'train_loss': 0.024010425433516502, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76878 < 77660; dropping {'train_loss': 0.11405391246080399, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76888 < 77660; dropping {'train_loss': 0.06207510456442833, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76898 < 77660; dropping {'train_loss': 0.18945012986660004, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76908 < 77660; dropping {'train_loss': 0.07750622183084488, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76918 < 77660; dropping {'train_loss': 0.013302161358296871, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76928 < 77660; dropping {'train_loss': 0.2422853410243988, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76938 < 77660; dropping {'train_loss': 0.04854418337345123, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76948 < 77660; dropping {'train_loss': 0.018464714288711548, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76958 < 77660; dropping {'train_loss': 0.974198579788208, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76968 < 77660; dropping {'train_loss': 1.0129027366638184, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76978 < 77660; dropping {'train_loss': 0.03656109794974327, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76988 < 77660; dropping {'train_loss': 0.08710400760173798, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 76998 < 77660; dropping {'train_loss': 0.11898616701364517, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77008 < 77660; dropping {'train_loss': 0.02032724767923355, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77018 < 77660; dropping {'train_loss': 0.02526767924427986, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77028 < 77660; dropping {'train_loss': 0.16325347125530243, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77038 < 77660; dropping {'train_loss': 0.03802035376429558, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77048 < 77660; dropping {'train_loss': 1.1884675025939941, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77058 < 77660; dropping {'train_loss': 0.01797572150826454, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77068 < 77660; dropping {'train_loss': 0.1810678392648697, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77078 < 77660; dropping {'train_loss': 0.2364315539598465, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77088 < 77660; dropping {'train_loss': 2.4430387020111084, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77098 < 77660; dropping {'train_loss': 0.06733012199401855, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77108 < 77660; dropping {'train_loss': 0.26969268918037415, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77118 < 77660; dropping {'train_loss': 0.03712446242570877, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77128 < 77660; dropping {'train_loss': 0.15511555969715118, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77138 < 77660; dropping {'train_loss': 0.480372816324234, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77148 < 77660; dropping {'train_loss': 0.05516548827290535, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77158 < 77660; dropping {'train_loss': 0.11650446802377701, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77168 < 77660; dropping {'train_loss': 0.025467606261372566, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77178 < 77660; dropping {'train_loss': 0.032999709248542786, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77188 < 77660; dropping {'train_loss': 0.01099295262247324, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77198 < 77660; dropping {'train_loss': 0.3709804117679596, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77208 < 77660; dropping {'train_loss': 0.14773176610469818, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77218 < 77660; dropping {'train_loss': 1.135810375213623, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77228 < 77660; dropping {'train_loss': 0.642766535282135, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77238 < 77660; dropping {'train_loss': 0.09644724428653717, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77248 < 77660; dropping {'train_loss': 0.2709006667137146, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77258 < 77660; dropping {'train_loss': 0.09620917588472366, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77268 < 77660; dropping {'train_loss': 0.04129935801029205, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77278 < 77660; dropping {'train_loss': 0.30224546790122986, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77288 < 77660; dropping {'train_loss': 0.09784471243619919, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77298 < 77660; dropping {'train_loss': 0.13659772276878357, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77308 < 77660; dropping {'train_loss': 0.015904054045677185, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77318 < 77660; dropping {'train_loss': 0.11266908794641495, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77328 < 77660; dropping {'train_loss': 0.8595563769340515, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77338 < 77660; dropping {'train_loss': 0.008296996355056763, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77348 < 77660; dropping {'train_loss': 0.171543151140213, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77358 < 77660; dropping {'train_loss': 0.011117038317024708, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77368 < 77660; dropping {'train_loss': 0.34275874495506287, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77378 < 77660; dropping {'train_loss': 0.3358181118965149, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77388 < 77660; dropping {'train_loss': 0.08223803341388702, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77398 < 77660; dropping {'train_loss': 0.12377706170082092, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77408 < 77660; dropping {'train_loss': 0.02407008223235607, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77418 < 77660; dropping {'train_loss': 0.48358893394470215, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77428 < 77660; dropping {'train_loss': 0.009137107990682125, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77438 < 77660; dropping {'train_loss': 0.0541885681450367, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77448 < 77660; dropping {'train_loss': 0.1792839914560318, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77458 < 77660; dropping {'train_loss': 2.51261305809021, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77468 < 77660; dropping {'train_loss': 0.012515532784163952, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77478 < 77660; dropping {'train_loss': 1.643827199935913, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77488 < 77660; dropping {'train_loss': 0.4755435883998871, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77498 < 77660; dropping {'train_loss': 0.13595779240131378, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77508 < 77660; dropping {'train_loss': 0.2271271049976349, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77518 < 77660; dropping {'train_loss': 1.4664756059646606, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77528 < 77660; dropping {'train_loss': 0.47913968563079834, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77538 < 77660; dropping {'train_loss': 0.017195912078022957, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77548 < 77660; dropping {'train_loss': 0.030052760615944862, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77558 < 77660; dropping {'train_loss': 0.0264673363417387, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77568 < 77660; dropping {'train_loss': 0.06053505465388298, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77578 < 77660; dropping {'train_loss': 0.019801905378699303, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77588 < 77660; dropping {'train_loss': 0.012085692957043648, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77598 < 77660; dropping {'train_loss': 0.39210405945777893, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77608 < 77660; dropping {'train_loss': 0.12143856287002563, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77618 < 77660; dropping {'train_loss': 0.050938669592142105, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77628 < 77660; dropping {'train_loss': 0.13149262964725494, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77638 < 77660; dropping {'train_loss': 0.13830578327178955, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77648 < 77660; dropping {'train_loss': 0.1631787121295929, 'epoch': 4}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 77658 < 77660; dropping {'train_loss': 0.26771894097328186, 'epoch': 4}.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fb582c1e72144eebbcd145a2c8698e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 89609 < 95582; dropping {'val_epoch_loss': 0.3547937870025635, 'val_epoch_auc': 0.9927627909738729, 'epoch': 4}.\n",
            "\n",
            "Epoch 00004: val_epoch_auc reached 0.99276 (best 0.99276), saving model to drive/My Drive/Colab Notebooks/checkpoints/DeepPavlov_mul-SBERT_epoch=4-val_epoch_auc=0.99.ckpt as top 1\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Adding to old History rows isn't currently supported.  Step 89610 < 95582; dropping {'train_epoch_loss': 0.278208464384079, 'epoch': 4}.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-70761f0c6e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DeepPavlov_mul-SBERT/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweigths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRUN_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/source/train.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model_class, config, project_name, run_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m                       resume_from_checkpoint='drive/My Drive/Colab Notebooks/checkpoints/DeepPavlov_mul-SBERT_epoch=1-val_epoch_auc=0.00.ckpt')\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/checkpoints/DeepPavlov_mul-SBERT'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLHc-yuPi7sv",
        "colab_type": "code",
        "outputId": "8e2ab5b5-3e05-42bd-e389-a9d3d0d0c6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "f2edc646c9b14e24888dfbe62cf715e5",
            "ea8a1509ef43422d9625bf17bae10be6",
            "cac793d473214351b372c41744efdf7b",
            "4052413eb345412d87266fee2d303334",
            "3fc7de8d6c4f4989850d9e5485e362c9",
            "f9e0ffae0b484212a8950e84fbe6b28b",
            "d6aca0884f9345d79dfbd3668938d8ce",
            "81abf07c6a974484a33c5ecb7ca8bef2",
            "52a995c7aebf4cc4864020df587440f5",
            "c89df62f97354ca6940de6d9c0b3ca35",
            "0e152ff30b094d68a9762a50135c35a9",
            "28e765b92d7247ad8591abb726bf2930",
            "9ad99e91d12f44728a177d18bdfb9dc6",
            "f6d280cf7efa4b75b7df129ae0f99fa6",
            "080a50c37f414d82922164c5cac29803",
            "bd93d1fd92ff4f0181a3e56548f5187a"
          ]
        }
      },
      "source": [
        "for file in os.listdir('drive/My Drive/Colab Notebooks/checkpoints'):\n",
        "  if file.endswith(\".ckpt\"):\n",
        "    ckpt_path = os.path.join('drive/My Drive/Colab Notebooks/checkpoints', file)\n",
        "\n",
        "model = ModelClass.load_from_checkpoint(ckpt_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2edc646c9b14e24888dfbe62cf715e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52a995c7aebf4cc4864020df587440f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711456796.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxY7NYBCW81B",
        "colab_type": "code",
        "outputId": "549b7ee7-92c3-4c91-b77c-805811ee5e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ef53b39bbfda4ef2864d61ecaa865017",
            "f9d039d1f15c4a8aa0d8257a944f833e",
            "2d6d594e179842e6b3d041aeb969bd80",
            "db210d6caa654761bfb0a8cff3337ba4",
            "714a29beb6e14e2f9e1b3a95a1cf3129",
            "a77514e14e5945b9a8c7d92a64104c66",
            "3fff2b8d135341eab5dfbdfbd26cf771",
            "e0e9a210bfee42f3bfdeec5ad1745e48",
            "5bea242cb9214fbd91e13838bafa5c16",
            "f62f0250a4524a49909f367d250e26c2",
            "a940e4bfdfef4a0cb739d206117a67c9",
            "186138a4b7e146619f41c26e7d1892e8",
            "1501b145424144d9b3f270c3b421c084",
            "14c272347d904869b85cb3f85bd7709a",
            "40b5a334fa824f91bcbdb53229f3dfb5",
            "0b5a28855def45aea377238683dbad44",
            "523eeebd529b4274ada0c052e6e277d0",
            "6b0e243aafa2464496136b2e38679eae",
            "d18f27fbc18643a89b59bb414cc699b0",
            "34d9a985216645a8b6d9ce64b9945f67",
            "8a652e14fef44847af86d49bd37f910d",
            "46535a077cfe4aeba731169c3c2de74c",
            "6f00a70c8d604529909af0b4e8eec3c2",
            "0064436c6fd04db99be0270f9659922b"
          ]
        }
      },
      "source": [
        "eval.evaluate(model, 'DeepPavlov_mul-SBERT', 'DeepPavlov_mul-SBERT')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef53b39bbfda4ef2864d61ecaa865017",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bea242cb9214fbd91e13838bafa5c16",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "523eeebd529b4274ada0c052e6e277d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=24.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTokenizing...:   0%|          | 0/71685 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenizing...: 100%|██████████| 71685/71685 [01:38<00:00, 724.72it/s]\n",
            "Predicting on cuda: 100%|██████████| 5974/5974 [1:06:20<00:00,  1.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro ROC-AUC = 0.9925629139262585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}